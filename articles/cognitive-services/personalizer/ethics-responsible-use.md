---
title: 倫理と責任ある使用 - Personalizer
titleSuffix: Azure Cognitive Services
description: これらのガイドラインは、会社およびサービスへの信頼の構築を助けるようなパーソナル化の実装を支援することを目的としています。 必ず、パーソナル化が人々の生活に与える影響を調査し、学び、慎重に検討してください。 疑問がある場合は、ガイダンスを求めてください。
services: cognitive-services
author: diberry
manager: nitinme
ms.service: cognitive-services
ms.subservice: personalizer
ms.topic: conceptual
ms.date: 06/12/2019
ms.author: diberry
ms.openlocfilehash: 11b626c0033814f0886ac76fff0c5d4087a80554
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/28/2020
ms.locfileid: "71720230"
---
# <a name="guidelines-for-responsible-implementation-of-personalizer"></a>Personalizer の責任ある実装のガイドライン

人と社会が AI の最大の可能性を実現するためには、アプリケーションに AI を追加した人たちや、AI を使って構築されたアプリケーションのユーザーから信頼を得られるように実装を設計する必要があります。 これらのガイドラインは、会社およびサービスへの信頼の構築を助けるような Personalizer の実装を支援することを目的としています。 必ず、パーソナル化が人々の生活に与える影響を調査し、学び、慎重に検討してください。 疑問がある場合は、ガイダンスを求めてください。

これらのガイドラインは法律に関する助言を意図したものではなく、お客様はご自身のアプリケーションが、この分野およびご自身のセクターで急速に策定が進む法律に準拠していることを別途確認する必要があります。

また、Personalizer を使用してアプリケーションを設計する際は、データ中心の AI システム開発時に負う、倫理、プライバシー、セキュリティ、安全性、包括性、透明性、説明責任を含む、広範囲にわたる責任について検討する必要があります。 これらの詳細については、「[推奨資料](#recommended-reading)」のセクションを参照してください。

次の内容をスターター チェックリストとして使用し、それをカスタマイズして、実際のシナリオに合うように調整できます。 このドキュメントには 2 つの主要なセクションがあります。1 つ目は、Personalizer のシナリオ、特徴、リワードを選択する際の責任ある使用について、考慮事項を強調することに専念しています。 2 つ目は、AI システムを構築する際に考慮する必要があると Microsoft が考える一連の価値に基づいて、Personalizer の使用がそれらにどのように影響するかについて、アクションにつながる提案とリスクを示します。 


## <a name="your-responsibility"></a>お客様の責任範囲

責任ある実装のためのすべてのガイドラインは、社会におけるこれらのアルゴリズムの使用の影響に対して責任を負い、説明責任を持つのは、Personalizer を使用する開発者と企業であるという基盤に基づいています。 自分の組織によってデプロイされるアプリケーションを開発する場合は、その運用に関する自分の役割および責任範囲と、そのアプリケーションがユーザーに与える影響を認識する必要があります。 サード パーティによってデプロイされるアプリケーションを設計する場合は、アプリケーションの動作に対して最終的に責任を負うのはだれなのかについて共通の理解に到達したうえで、その理解を文書化します。

信頼は、約束を果たすという概念に基づいて構築されます。ユーザー、社会、アプリケーションを運用する法的枠組みを考慮して、明示的および暗黙的なコミットメントを識別します。

Microsoft では、お客様がこれらの責任に基づいて行動するのを助けるために、ツールとドキュメントに対する作業を続けています。 Personalizer の使用に関するこれらのガイドラインの実装に役立つと思われる追加のツール、製品機能、ドキュメントがありましたら、[Microsoft までフィードバックをお送りください](mailto:cogsvcs-RL-feedback@microsoft.com?subject%3DPersonalizer%20Responsible%20Use%20Feedback&body%3D%5BPlease%20share%20any%20question%2C%20idea%20or%20concern%5D)。


## <a name="factors-for-responsibly-implementing-personalizer"></a>責任を持って Personalizer を実装するための要因

Personalizer を実装することは、ご自身のユーザーとビジネスにとって大きな価値になる可能性があります。 責任を持って Personalizer を実装するには、まず次に示すガイドラインを以下の場合に検討してください。

* パーソナル化を適用するユース ケースを選択する。
* [リワード関数](https://github.com/Azure/personalization-rl/blob/master/docs/concepts-rewards.md)を構築する。
* コンテキストと可能なアクションについて、どの[特徴](https://github.com/Azure/personalization-rl/blob/master/docs/concepts-features.md)をパーソナル化に使用するかを選択する。


## <a name="choosing-use-cases-for-personalizer"></a>Personalizer のユース ケースを選択する

コンテンツとユーザー インターフェイスをパーソナル化することを学習するサービスを使用すると、便利です。 それはまた、パーソナル化によって現実の世界にマイナスの副作用が生じるような方法で誤って適用される可能性もあります。これには、ユーザーがコンテンツのパーソナル化に気付いていない場合を含みます。 

マイナスの副作用や透明性の欠如が生じる可能性の高い Personalizer の使用例として、"リワード" が長期的で複雑な多くの要因に依存しているシナリオにおいて、即時リワードまで過度に単純化されたときに、個人にとって好ましくない結果になることがあります。 これらは "結果的" な選択、または損害を及ぼすリスクを含む選択と見なされる傾向にあります。 次に例を示します。 


* **ファイナンス**: リスク要因が、個人が知らない、入手できない、または争うことができないデータに基づいた、ローン、金融、保険商品のオファーをパーソナル化します。 
* **教育**:レコメンデーションがバイアス (偏り) を伝達し、他のオプションに対するユーザーの認識を低下させる可能性がある、学校のコースおよび教育機関のランクをパーソナル化します。
* **民主主義と市民参加**: 意見に影響を与えることを目的としたユーザー向けコンテンツのパーソナル化は、結果的であり操作可能です。
* **第三者のリワード評価**: ユーザー自身の行動によってリワードが生成されるのではなく、リワードが後者の第三者評価に基づいている項目をパーソナル化します。
* **探索に対する不寛容**: Personalizer の探索動作が害を及ぼす可能性がある、あらゆる状況。

Personalizer のユース ケースを選ぶ場合:

* パーソナル化がどのようにユーザーに役立つかを考慮しながら設計プロセスを開始します。
* パーソナル化のパターンまたは探索が原因で一部の項目がユーザーに対してランク付けされなかった場合の、現実の世界でのマイナスの結果を考慮します。
* ユース ケースが、[GDPR](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32016R0679) 第 22 項または他の法律によって規制されているデータ主体に大きな影響を及ぼす自動処理を構成するかどうかを検討します。
* 自己実現的な予言ループを考えてみましょう。 これは、パーソナル化のリワードによってモデルがトレーニングされ、結果的に人口統計グループが関連コンテンツへのアクセスからさらに除外される可能性がある場合に、発生する可能性があります。 たとえば、低所得地域のほとんどの人は、高い保険料のオファーを受けておらず、徐々に、よく調べないと地域のだれもオファーをまったく見なくなる傾向があります。
* 今後 Personalizer を再現することが必要になった場合に備えて、モデルと学習ポリシーのコピーを保存します。 これは、定期的に、またはモデル更新期間ごとに行うことができます。
* 空間に適した探索のレベルと、それを "エコー チェンバー" 効果を軽減するためのツールとして使用する方法を検討します。


## <a name="selecting-features-for-personalizer"></a>Personalizer の特徴を選択する

コンテンツのパーソナル化は、コンテンツとユーザーに関する有用な情報を持っていることに依存します。 アプリケーションと業種によっては、ユーザーの特徴の一部は直接的または間接的に差別的であり、潜在的に違法と見なされることに注意してください。

これらの特徴の効果を検討します。

* **ユーザーの人口統計情報**: 性別、年齢、人種、宗教に関する特徴: これらの特徴は、規制上の理由から特定のアプリケーションでは使用できない場合があります。また、パーソナル化によって一般化とバイアスが伝達されるため、それらの特徴に基づいてパーソナル化することは倫理的でない可能性があります。 このバイアスの伝達の例は、高齢や性別に基づいた対象者に表示されないエンジニアの求人掲載です。
* **ロケール情報**: 世界の多くの場所で、位置情報 (郵便番号、地域名など) は、収入、人種、宗教と高い相関関係があります。
* **ユーザーによる公平性の認識**: アプリケーションによって適切な決定が行われている場合でも、アプリケーションに表示されるそのコンテンツが、差別的な可能性のある特徴と関連付けられているように変化していることをユーザーが認識しているとしたら、どのような影響があるかを検討します。
* **特徴における意図しないバイアス**: 母集団のサブセットにのみ影響を与える特徴を使用することで生じる可能性がある種類のバイアスがあります。 画像内の項目を抽出するために画像分析を使用する場合や、テキスト内のエンティティを検出するためにテキスト分析を使用する場合など、特徴がアルゴリズムで生成される場合、これには特別な注意が必要です。 これらの特徴を作成するために使用するサービスの特性を自身で認識してください。

コンテキストおよびアクションで Personalizer に送信する特徴を選択するときは、以下のプラクティスを適用します。

* 一部のアプリケーションに特定の特徴を使用することの合法性と倫理を検討し、無害に見える特徴が、回避したい、または回避すべき他の特徴への中継点となる可能性があるかどうかを検討します。
* 表示されるオプションをパーソナル化するためにアルゴリズムとデータ分析を使っていることがユーザーにわからないようにします。
* 次のことを確認してください。この情報を使用してユーザー用のコンテンツをパーソナル化した場合、ユーザーは気にするか、そして満足するでしょうか。 特定の項目を強調表示または非表示にするための決定がどのように行われたかをユーザーに示すことに抵抗を感じないでしょうか。
* 他の特性に基づいた分類や区分データではなくふるまいに基づいたデータを使用します。 人口統計情報は、歴史的な理由で小売業者によって伝統的に使用されていました。デジタル時代よりも前、人口統計情報は収集と処理が簡単だと思われていました。しかし、ユーザーの好みやアイデンティティにより密接に関連する実際のやり取り、コンテキスト、および履歴データがある場合、人口統計情報にどれだけ関連性があるのかについては疑問です。
* 悪意のあるユーザーによって特徴が "なりすまし" されないようにする方法を検討します。これは、大量に悪用されると、特定のユーザー クラスを意図的に妨害、恥ずかしめ、嫌がらせをする誤解を招くような方法で Personalizer がトレーニングされることにつながる可能性があります。 
* 適切で実行可能な場合は、ユーザーが特定の個人的特徴を使用することをオプトインまたはオプトアウトできるようにアプリケーションを設計します。 これらは、"位置情報"、"デバイス情報"、"過去の購入履歴" のようにグループ化できます。


## <a name="computing-rewards-for-personalizer"></a>Personalizer のリワードの計算

Personalizer では、アプリケーションのビジネス ロジックによって提供されるリワード スコアに基づいて、どのアクションにリワードを与えるかの選択を改善するように努力しています。

適切に構築されたリワード スコアは、組織の使命に結び付けられた、ビジネス目標の短期的な中継点として機能します。

たとえば、クリックに対してリワードを与えると、クリックされた対象が妨げになるものであったりビジネス上の結果に結び付けられていなかったとしても、Personalizer Service では他のすべてを犠牲にしてクリックを探すようになります。

対照的な例として、ニュース サイトでは、クリック数よりも意味のあるもの (例えば "ユーザーはコンテンツを読むのに十分な時間を費やしたか?" "関連する記事や参考文献をクリックしたか?" ) に結び付けられたリワードを設定することができます。 Personalizer を使用すると、メトリックとリワードを密接に結び付けることが簡単にできます。 しかし、短期間のユーザー エンゲージメントを望ましい結果と混同しないように注意してください。

### <a name="unintended-consequences-from-reward-scores"></a>リワード スコアによる意図しない結果
リワード スコアは最善の意図で構築することができますが、それでも Personalizer でのコンテンツのランク付け方法に予期しない結果や意図しない結果をもたらす可能性があります。 

次の例を考えてみます。

* 視聴されたビデオの長さにリワードを与えるビデオ コンテンツのパーソナル化には、おそらく短いビデオがランク付けされます。
* ソーシャル メディアの共有にリワードを与える場合、共有された方法やコンテンツ自体の感情分析がなければ、不快なコンテンツ、過激なコンテンツ、炎上しやすいコンテンツのランク付けにつながる可能性があります。それらは多くの "エンゲージメント" を起こしますが、追加される価値はほとんどありません。
* ユーザーが変更を期待していないユーザー インターフェイス要素に対するアクションにリワードを与えると、ユーザー インターフェイスの使いやすさや予測可能性の妨げになる可能性があり、ボタンの位置や目的が警告なしに驚くほど変更されて、特定のユーザー グループにとって生産性を維持することが難しくなります。

これらのベスト プラクティスを実装します。

* 影響と副作用を理解するために、ご自身のシステムでさまざまなリワードのアプローチを使用してオフライン実験を実行します。
* リワード関数を評価し、極端に素朴な人がどのような方法でその解釈を曲げて望ましくない結果に到達するかを確認します。


## <a name="responsible-design-considerations"></a>責任ある設計に関する考慮事項

責任ある AI の実装のための設計の領域を次に示します。 このフレームワークの詳細については、[The Future Computed](https://news.microsoft.com/futurecomputed/) のページを参照してください。

![Future Computed での AI の価値](media/ethics-and-responsible-use/ai-values-future-computed.png)

### <a name="accountability"></a>アカウンタビリティ
*AI システムを設計してデプロイするユーザーは、自分たちのシステムがどのように動作するかについて説明責任があります*。 

* Personalizer の実装方法に関する社内ガイドラインを作成し、文書化して、チーム、幹部、サプライヤーに伝達します。
* リワード スコアの計算方法を定期的に見直し、オフライン評価を実行して Personalizer に影響を与えている特徴を確認します。そして、その結果を使用して、望ましくない特徴と不要な特徴を排除します。
* Personalizer を使用する方法と目的、およびどのようなデータに使用するかをユーザーに明確に伝えます。
* Personalizer が機能するために使用される情報と資産 (モデル、学習ポリシー、その他のデータなど) をアーカイブして、結果を再現できるようにします。

### <a name="transparency"></a>透明性
*AI システムは理解可能である必要があります*。 Personalizer 使用時には:

* *コンテンツがどのような方法でパーソナル化されたかについてユーザーに情報を与えます。* たとえば、`Why These Suggestions?` というラベルの付いたボタンをユーザーに表示して、ユーザーとアクションのどのような最上位の特徴が、Personalizer の結果において役割を果たしたかを示すことができます。
* 利用規約において、ユーザーおよびユーザーのふるまいに関する情報を使ってエクスペリエンスをパーソナル化することに必ず言及します。

### <a name="fairness"></a>公平性
"*AI システムでは、すべてのユーザーを公平に扱う必要があります*"。

* 結果が長期的または結果的であるか、実際の損害を含むユース ケースには Personalizer を使用しないでください。
* コンテンツのパーソナル化に使用することが適切でない特徴、または望ましくないバイアスを伝達することにつながる可能性がある特徴は、使わないでください。 たとえば、財務状況が似ている人はだれでも、金融商品について同じパーソナル化されたレコメンデーションを参照することになります。
* エディター、アルゴリズム ツール、またはユーザー自身を提供元とする特徴の中に存在する可能性があるバイアスについて理解します。

### <a name="reliability-and-safety"></a>信頼性と安全性
*AI システムを確実かつ安全に実行する必要があります*。 Personalizer の場合:

* *選択されるべきでないアクションを Personalizer に指定しないでください*。 たとえば、匿名または未成年のユーザー向けのレコメンデーションを作成する場合、不適切なムービーはパーソナル化するアクションから除外される必要があります。
* *Personalizer モデルをビジネス資産として管理します*。  Personalizer ループの背後にあるモデルと学習ポリシーを保存およびバックアップする頻度を検討します。そうしない場合は、重要なビジネス資産として扱います。 過去の結果を再現することは、自己監査と改善の測定のために重要です。
* *ユーザーから直接フィードバックを得るためのチャネルを提供します*。 適切な対象者だけに適切なコンテンツが確実に表示されるように安全性チェックをコーディングすることに加えて、驚くようなコンテンツや不快なコンテンツを報告するためのフィードバック メカニズムを提供します。 特に、コンテンツがユーザーまたはサードパーティからのものである場合は、Microsoft Content Moderator または追加のツールを使用して、コンテンツを確認および検証することを検討してください。
* *オフライン評価を頻繁に実行します*。 これは、傾向を監視して有効性を確実に把握するのに役立ちます。
* *悪意のある操作を検出して対処するためのプロセスを確立します*。 機械学習と AI システムの環境から学習する能力を活用して、結果を目標に向かってシフトするアクターが存在します。 Personalizer の使用が重要な選択に影響を与えると位置付けられる場合は、適切な状況での人間によるレビューを含め、これらの分類の攻撃を検出して軽減するための適切な手段を確保してください。

### <a name="security-and-privacy"></a>セキュリティとプライバシー
*AI システムは安全で、プライバシーを尊重する必要があります*。 Personalizer を使用する場合:

* *収集されるデータとその使用方法についてユーザーに事前に通知し、* 地域および業界の規制に従って事前に同意を得ます。
* *プライバシーを保護するユーザー コントロールを提供します。* 個人情報を保存するアプリケーションの場合は、次のような関数について、簡単に見つけられるボタンを提供することを検討してください。 
   * `Show me all you know about me`    
   * `Forget my last interaction` 
   * `Delete all you know about me`

場合によっては、これらは法的に必須になることがあります。 モデルを定期的に再トレーニングする際のトレードオフを考慮し、削除されたデータの痕跡が含まれないようにします。

### <a name="inclusiveness"></a>包括性
*幅広い人間のニーズと経験に対応させます*。
* *アクセシビリティに対応したインターフェイス用のパーソナル化されたエクスペリエンスを提供します。* 優れたパーソナル化から得られる効率性 (労力、移動、対話的操作における不必要な繰り返しを減らすために適用される) は、障碍を持つ人にとって特に有益です。
* *コンテキストに合わせてアプリケーションの動作を調整します*。 Personalizer を使用してチャットボットにおける複数の意図の間のあいまいさをなくすことができます。たとえば、正しい解釈はコンテキストに依存し、1 つのサイズがすべてに適合するとは限りません。 


## <a name="proactive-readiness-for-increased-data-protection-and-governance"></a>データ保護とガバナンスを強化するためのプロアクティブな対応

規制のコンテキストにおける具体的な変化を予測することは困難ですが、一般に、個人データを確実に尊重しながら使用し、アルゴリズムの意思決定に関する透明性と選択肢を提供するには、最低限の法的枠組みを超えることが賢明です。


* 個人から収集したデータに対して新たな制限が課される可能性があり、それが意思決定にどのように使用されたかを示す必要がある状況に備えて、事前に計画することを検討してください。
* ユーザーが、疎外されている脆弱な集団、子供、経済的に脆弱なユーザー、またはそれ以外のアルゴリズム操作の影響を受けやすいユーザーを含む可能性がある場合に備えた、特別な準備について検討します。
* 対象ユーザーを指定し、対象ユーザーに影響を与えるデータ収集プログラムとアルゴリズムの成果、および実証済みの戦略エラーを回避する方法について、広い範囲にわたる不満を検討してください。


## <a name="proactive-assessments-during-your-project-lifecycle"></a>プロジェクト ライフサイクル中のプロアクティブな評価

チーム メンバー、ユーザー、および事業主が責任ある使用に関する懸念を報告するための方法を作成し、その解決を優先して報復を防止するプロセスを作成することを検討します。

任意の技術を使用することの副作用について考える人はだれでも、自身の視点と人生経験による制限を受けます。 ご自身のチーム、ユーザー、または諮問委員会に、より多様な意見を取り入れることによって、利用可能な意見の範囲を広げます。それにより、それらの人たちが声を挙げることが可能になるとともに、奨励されるようになります。 この分野におけるチームの知識をさらに広げ、複雑で繊細なトピックについて話し合えるようにするためのトレーニングや教材を検討してください。

責任ある使用に関するタスクを、アプリケーション ライフサイクルにおける他の分野横断的なタスク (ユーザー エクスペリエンス、セキュリティ、DevOps に関連するタスクなど) とまったく同じように処理することを検討してください。 これらのタスクとその要件を後回しにすることはできません。 責任ある使用は、アプリケーションのライフサイクル全体を通して話し合い、検証する必要があります。
 
## <a name="questions-and-feedback"></a>質問とフィードバック

Microsoft では、お客様がこれらの責任に基づいて行動するのを助けるために、ツールとドキュメントに対する作業を続けています。 担当チームより、Personalizer の使用に関するこれらのガイドラインの実装に役立つと思われる追加のツール、製品機能、ドキュメントがありましたら、[Microsoft までフィードバックをお送りくださるようお願いします](mailto:cogsvcs-RL-feedback@microsoft.com?subject%3DPersonalizer%20Responsible%20Use%20Feedback&body%3D%5BPlease%20share%20any%20question%2C%20idea%20or%20concern%5D)。

## <a name="recommended-reading"></a>推奨資料

* AI の責任ある開発に関する Microsoft の 6 つの原則を、2018 年 1 月に発行された書籍「[The Future Computed](https://news.microsoft.com/futurecomputed/)」でご確認ください。
* 「[Who Owns the Future?](https://www.goodreads.com/book/show/15802693-who-owns-the-future)」(未来を所有するのはだれ?)、Jaron Lanier 著
* 「[Weapons of Math Destruction](https://www.goodreads.com/book/show/28186015-weapons-of-math-destruction)」(数学破壊兵器)、Cathy O'Neil 著
* 「[Ethics and Data Science](https://www.oreilly.com/library/view/ethics-and-data/9781492043898/)」(倫理とデータ科学)、DJ Patil、Hilary Mason、Mike Loukides 著
* [ACM 倫理規定](https://www.acm.org/code-of-ethics)
* [遺伝情報差別禁止法 - GINA](https://en.wikipedia.org/wiki/Genetic_Information_Nondiscrimination_Act)
* [FATML の説明可能なアルゴリズムの原則](https://www.fatml.org/resources/principles-for-accountable-algorithms)


## <a name="next-steps"></a>次のステップ

[特徴: アクションとコンテキスト](concepts-features.md).
