---
title: Custom Speech モデルのトレーニングとデプロイ - 音声サービス
titleSuffix: Azure Cognitive Services
description: Custom Speech モデルをトレーニングおよびデプロイする方法について説明します。 音声テキスト変換モデルをトレーニングすると、Microsoft のベースライン モデルまたはカスタム モデルの認識精度を向上できます。
services: cognitive-services
author: trevorbye
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 02/12/2021
ms.author: trbye
ms.openlocfilehash: 166fb94f5a3aea505c0d20df861b8bc4de9ad8aa
ms.sourcegitcommit: 772eb9c6684dd4864e0ba507945a83e48b8c16f0
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/20/2021
ms.locfileid: "103491114"
---
# <a name="train-and-deploy-a-custom-speech-model"></a>Custom Speech モデルのトレーニングとデプロイ

この記事では、Custom Speech モデルをトレーニングおよびデプロイする方法について説明します。 音声テキスト変換モデルをトレーニングすると、Microsoft のベースライン モデルの認識精度を向上できます。 "人間" とラベルが付いた文字起こしと関連するテキストを使用してモデルをトレーニングします。 これらのデータセットは、以前にアップロードされたオーディオ データと共に、音声テキスト変換モデルの調整とトレーニングに使われます。

## <a name="use-training-to-resolve-accuracy-problems"></a>トレーニングを使用して正確性の問題を解決する

ベース モデルで認識の問題が発生している場合は、カスタム モデルのトレーニングに "人間" とラベルが付いたトランスクリプトと関連データを使用すると、精度を向上させることができます。 この表を使用して、問題の対処に使用するデータセットを決定します。

| 使用事例 | データ型 |
| -------- | --------- |
| 医療用語や IT 用語のような業界固有の語彙や文法に対する認識精度を向上させる。 | 関連テキスト (文/発話) |
| 製品名や頭字語のような、発音が標準ではない単語または用語の表音および表示形式を定義する。 | 関連テキスト (発音) |
| 読み上げのスタイル、アクセント、または特定の背景ノイズの認識精度を向上させる | "オーディオ + 人間" とラベルが付いたトランスクリプト |

## <a name="train-and-evaluate-a-model"></a>モデルのトレーニングと評価

モデルをトレーニングする最初の手順は、トレーニング データのアップロードです。 "人間" とラベルが付いた文字起こしと関連テキスト (発話と発音) を準備する手順については、[データの準備とテスト](./how-to-custom-speech-test-and-train.md)に関する記事を参照してください。 トレーニング データをアップロードしたら、次の手順に従ってモデルのトレーニングを開始します。

1. [Custom Speech ポータル](https://speech.microsoft.com/customspeech)にサインインします。 オーディオ + 人間によってラベル付けされた文字起こしデータセットを使用してモデルをトレーニングする場合は、トレーニング用の[専用のハードウェアを持つリージョン](custom-speech-overview.md#set-up-your-azure-account)の Speech サブスクリプションを選択します。
2. **[音声テキスト変換]**  >  **[Custom Speech]**  >  **[<プロジェクト名>]**  >  **[トレーニング]** の順に移動します。
3. **[モデルのトレーニング]** を選択します。
4. トレーニングの **[名前]** と **[説明]** を指定します。
5. **[Scenario and Baseline model]\(シナリオとベースライン モデル\)** リストで、ご自分のドメインに最適なシナリオを選択します。 どのシナリオを選択すればよいかわからない場合は、 **[一般]** を選択します。 このベースライン モデルがトレーニングの開始点です。 通常は、最新のモデルが最適な選択肢です。
6. **[Select training data]\(トレーニング データの選択\)** ページで、関連するテキスト データセット、またはトレーニングに使用するオーディオ + 人間によってラベル付けされた文字起こしデータセットを 1 つ以上選択します。

> [!NOTE]
> 新しいモデルをトレーニングするときは、関連するテキストから開始します。オーディオ + 人間によってラベル付けされた文字起こしを使用したトレーニングは、かなり長い時間がかかる場合があります **(最大 [数日](how-to-custom-speech-evaluate-data.md#add-audio-with-human-labeled-transcripts)** )。

> [!NOTE]
> すべての基本モデルでオーディオのトレーニングがサポートされるわけではありません。 基本モデルでサポートされていない音声サービスは、トランスクリプトのテキストのみを使用し、オーディオを無視します。 オーディオ データを使用したトレーニングをサポートする基本モデルの一覧については、「[言語のサポート](language-support.md#speech-to-text)」を参照してください。

> [!NOTE]
> トレーニングに使用する基本モデルを変更し、トレーニング データセットにオーディオが含まれる場合は、選択した新しい基本モデルが [オーディオ データを使用したトレーニングをサポート](language-support.md#speech-to-text)しているかどうかを "*常に*" 確認します。 以前使用した基本モデルでオーディオ データを使用したトレーニングがサポートされておらず、トレーニング データセットにオーディオが含まれる場合は、新しい基本モデルを使用したトレーニングの時間が **大幅に** 増加し、数時間から数日以上かかる可能性が大いにあります。 これは特に、音声サービスのサブスクリプションが、トレーニング用の [専用ハードウェアがあるリージョン](custom-speech-overview.md#set-up-your-azure-account)に **存在しない** 場合に当てはまります。
>
> 上の段落で説明されている問題が発生した場合、データセット内のオーディオの量を減らすか、完全に削除してテキストのみを残すことで、トレーニング時間を簡単に短縮できます。 音声サービスのサブスクリプションが、トレーニング用の [専用ハードウェアがあるリージョン](custom-speech-overview.md#set-up-your-azure-account)に **存在しない** 場合、後者のオプションを強くお勧めします。

7. トレーニングが完了したら、新しくトレーニングしたモデルに対して正確性テストを行うことができます。 この手順は省略可能です。
8. **[作成]** を選択してカスタム モデルを作成します。

**[トレーニング]** の表に、新しいモデルに対応する新しいエントリが表示されます。 この表には、次の状態も表示されます。 **[処理中]** 、 **[成功]** 、 **[失敗]** 。

Custom Speech モデルの精度の評価と向上については、[方法](how-to-custom-speech-evaluate-data.md)に関する記事を参照してください。 正確性のテストを選択する場合、現実的なモデルのパフォーマンスを把握するために、モデルで使用したものとは異なる音響データセットを選択することが重要です。

> [!NOTE]
> 基本モデルとカスタム モデルはどちらも、特定の日付までしか使用できません (「[モデルとエンドポイントのライフサイクル](./how-to-custom-speech-model-and-endpoint-lifecycle.md)」を参照)。 Speech Studio では、各モデルとエンドポイントの **[有効期限]** 列にこの日付が表示されます。 その日付以降は、エンドポイントへの要求やバッチ文字起こしの要求が失敗したり、基本モデルにフォールバックしたりする可能性があります。
>
> 精度の向上を実現し、モデルの有効期限が切れないようにするには、最新の基本モデルを使用してモデルを再トレーニングしてください。

## <a name="deploy-a-custom-model"></a>カスタム モデルをデプロイする

データをアップロードして検査し、正確性を評価し、カスタム モデルをトレーニングしたら、アプリ、ツール、および製品で使用するカスタム エンドポイントをデプロイできます。 

カスタム エンドポイントを作成するには、[Custom Speech ポータル](https://speech.microsoft.com/customspeech)にサインインします。 ページの上部にある **[Custom Speech]** メニューで、 **[デプロイ]** を選択します。 これが最初の実行の場合は、表に記載されているエンドポイントがないことがわかります。 エンドポイントを作成したら、このページを使用して、デプロイされた各エンドポイントを追跡します。

次に、 **[エンドポイントの追加]** を選択し、カスタム エンドポイントの **[名前]** と **[説明]** を入力します。 次に、エンドポイントに関連付けるカスタム モデルを選択します。  このページから、ログを有効にすることもできます。 ログを使用すると、エンドポイントのトラフィックを監視できます。 ログを無効にすると、トラフィックは保存されません。

![[新しいエンドポイント] ページを示しているスクリーンショット。](./media/custom-speech/custom-speech-deploy-model.png)

> [!NOTE]
> 必ず使用条件と価格の詳細に同意します。

次に、 **[作成]** を選択します。 この操作によって、 **[デプロイ]** ページに戻ります。 表には、カスタム エンドポイントに対応するエントリが含まれています。 エンドポイントの状態は現在の状態を示しています。 カスタム モデルを使用して新しいエンドポイントをインスタンス化するには、最大で 30 分かかることがあります。 デプロイの状態が **[完了]** に変わると、エンドポイントは使用できる状態です。

ご自分のエンドポイントがデプロイされると、エンドポイント名はリンクとして表示されます。 リンクを選択すると、エンドポイント キー、エンドポイントの URL、サンプル コードなど、ご自分のエンドポイントに固有の情報が表示されます。 サービスが中断されないようにするには、有効期限をメモし、その日より前にエンドポイントのモデルを更新します。

## <a name="view-logging-data"></a>ログ データを表示する

**[デプロイ]** の下でエンドポイントのページに移動すると、ログ データをエクスポートできます。
> [!NOTE]
>ログ データは、Microsoft が所有するストレージで 30 日間使用できます。 その後、削除されます。 お客様が所有するストレージ アカウントが Cognitive Services サブスクリプションにリンクされている場合は、ログ データは自動的に削除されません。

## <a name="next-steps"></a>次のステップ

* [カスタム モデルの使用方法を学習する](how-to-specify-source-language.md)

## <a name="additional-resources"></a>その他のリソース

- [データを準備してテストする](./how-to-custom-speech-test-and-train.md)
- [データを検査する](how-to-custom-speech-inspect-data.md)
- [データを評価する](how-to-custom-speech-evaluate-data.md)
