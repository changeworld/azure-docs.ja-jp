---
title: 音声テキスト変換についてよく寄せられる質問
titleSuffix: Azure Cognitive Services
description: 音声テキスト変換についてよく寄せられる質問の回答を紹介します。
services: cognitive-services
author: PanosPeriorellis
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 02/01/2021
ms.author: panosper
ms.openlocfilehash: f71fd01d45604dff843ad6eba62561937366a125
ms.sourcegitcommit: 77d7639e83c6d8eb6c2ce805b6130ff9c73e5d29
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 04/05/2021
ms.locfileid: "106382336"
---
# <a name="speech-to-text-frequently-asked-questions"></a>音声テキスト変換についてよく寄せられる質問

疑問点への回答がこのよく寄せられる質問で見つからない場合は、[その他のサポート オプション](../cognitive-services-support-options.md?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext%253fcontext%253d%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext)を確認してください。

## <a name="general"></a>全般

**Q:音声テキスト変換のベースライン モデルとカスタム音声テキスト変換の違いは何ですか。**

**A**: ベースライン モデルは Microsoft 所有のデータを使用してトレーニングされており、事前にクラウドにデプロイされています。 カスタム モデルを使用すると、特定のアンビエント ノイズまたは言語がある特定の環境にさらに合うようにモデルを調整できます。 工場の現場、車の中、または騒音の多い道路などでは、適合させた音響モデルが必要です。 生物学、物理学、放射線学、製品名、およびカスタムの頭字語などのトピックには、適合させた言語モデルが必要になることがあります。 カスタム モデルをトレーニングする場合は、特別な用語や語句の認識を向上させるために、関連テキストから始める必要があります。

**Q:ベースライン モデルの使用はどこから開始できますか。**

**A**: 最初に、[サブスクリプション キー](overview.md#try-the-speech-service-for-free)を取得します。 事前にデプロイされたベースライン モデルに対して REST 呼び出しを実行する方法については、「[REST API](./overview.md#reference-docs)」を参照してください。 WebSocket を使用する場合は、[SDK](speech-sdk.md) をダウンロードしてください。

**Q:カスタム音声モデルを常にビルドする必要はありますか。**

**A**: いいえ。 アプリケーションが一般的な日常の言語を使用している場合、モデルをカスタマイズする必要はありません。 アプリケーションが背景ノイズのほんとどない環境で使用されている場合も、モデルをカスタマイズする必要はありません。

ベースライン モデルとカスタマイズしたモデルをポータルでデプロイし、それらに対して正確性テストを実行できます。 この機能を使用して、ベースライン モデルとカスタム モデルの正確性を測定して比較できます。

**Q:データセットまたはモデルの処理が完了した場合にはそれをどのように知ることができますか。**

**A**: 現在、それを知る唯一の方法はテーブル内のモデルやデータ セットの状態です。 処理が完了すると、その状態は **[成功]** になります。

**Q:複数のモデルを作成できますか。**

**A**: コレクション内のモデル数に制限はありません。

**Q:ミスをしてしまったことに気付きました。進行中のデータのインポートやモデルの作成をキャンセルするにはどうすればよいですか。**

**A**: 現在、音響モデルや言語モデルの適応処理はロールバックできません。 インポートされたデータやモデルは、終了状態になれば削除できます。

**Q:各語句について、詳細な出力形式でいくつかの結果が得られます。どれを使用すればよいですか。**

**A**: 別の結果 ("N-Best") の信頼度の値が高い場合でも、常に最初の結果を使用します。 音声サービスでは、最初の結果が最適であると見なされます。 また、音声が認識されなかった場合は、空の文字列になることもあります。

その他の結果は、適していない可能性が高く、完全な大文字化や句読点が適用されていない可能性があります。 これらの結果が最も役立つのは、リストから修正内容を選択するオプションをユーザーに提供したり、不適切に認識されたコマンドを処理したりするなど、特別なシナリオで最も役立ちます。

**Q:異なる基本モデルがあるのはなぜですか。**

**A**: 音声サービスでは、複数の基本モデルから選択できます。 各モデルの名前には、追加された日付が含まれています。 カスタム モデルのトレーニングを開始するときは、最適な精度を得られるように最新のモデルを使用してください。 新しいモデルを使用できるようになっても、しばらくは以前の基本モデルを利用できます。 使用していたモデルは、廃止されるまで引き続き使用できます (「[モデルとエンドポイントのライフサイクル](./how-to-custom-speech-model-and-endpoint-lifecycle.md)」を参照)。 ただし、精度を高めるために、最新の基本モデルに切り替えることをお勧めします。

**Q:既存のモデル (モデル スタッキング) を更新できますか。**

**A**: 既存のモデルは更新できません。 解決策として、以前のデータセットを新しいデータセットと結合し、新たに調整してください。

古いデータセットと新しいデータセットは、単一の .zip ファイル (音響データの場合) または .txt ファイル (言語データの場合) に組み合わせて使用する必要があります。 適応が完了したら、新しいエンドポイントを取得するために、新しく更新されたモデルのデプロイを解除する必要があります

**Q:新しいバージョンの基本モデルが利用可能になると、デプロイは自動的に更新されますか。**

**A**: デプロイは自動的には更新されません。

モデルを適応させてデプロイした場合、そのデプロイはそのまま残ります。 デプロイ済みのモデルを解除し、新しいバージョンの基本モデルを使用し、再び適応させて再デプロイすると、精度を高めることができます。

基本モデルとカスタム モデルはしばらくすると廃止されます (「[モデルとエンドポイントのライフサイクル](./how-to-custom-speech-model-and-endpoint-lifecycle.md)」を参照)。

**Q:自分のモデルをダウンロードしてローカルで実行できますか。**

**A**: カスタム モデルは [Docker コンテナー](speech-container-howto.md?tabs=cstt)でローカルに実行できます。

**Q:データセット、モデル、デプロイを別のリージョンまたはサブスクリプションにコピーまたは移動することはできますか。**

**A**: [REST API](https://centralus.dev.cognitive.microsoft.com/docs/services/speech-to-text-api-v3-0/operations/CopyModelToSubscription) を使用して、カスタム モデルを別のリージョンまたはサブスクリプションにコピーできます。 データセットまたはデプロイをコピーすることはできません。 別のサブスクリプションにもう一度データセットをインポートし、そこでモデル コピーを使用してエンドポイントを作成できます。

**Q:個人の要求はログに記録されますか。**

**A**: 既定では、要求は (音声と文字起こしのどちらにも) ログに記録されません。 必要であれば、[カスタム エンドポイントを作成する](how-to-custom-speech-train-model.md#deploy-a-custom-model)ときに、 *[Log content from this endpoint]\(このエンドポイントからコンテンツをログに記録する\)* オプションを選択できます。 また、カスタム エンドポイントを作成せずに、[Speech SDK](how-to-use-logging.md) で、要求ごとにオーディオ ログを有効にすることもできます。 どちらの場合も、要求のオーディオと認識の結果は、セキュリティで保護されたストレージに格納されます。 Microsoft が所有するストレージを使用するサブスクリプションでは、30 日間使用できます。

*[Log content from this endpoint]\(このエンドポイントからコンテンツをログに記録する\)* が有効になっているカスタム エンドポイントを使用している場合は、Speech Studio のデプロイ ページでログのファイルをエクスポートできます。 SDK を介してオーディオ ログが有効になっている場合は、[API](https://centralus.dev.cognitive.microsoft.com/docs/services/speech-to-text-api-v3-0/operations/GetBaseModelLogs) を呼び出してファイルにアクセスします。

**Q:ユーザーの要求は調整されますか。**

**A**: 「[Speech Services のクォータと制限](speech-services-quotas-and-limits.md)」を参照してください。

**Q:デュアル チャネル オーディオの料金はどのように課金されますか。**

**A**: 各チャネルを個別に送信した場合 (各チャネルは独自のファイルにあります)、各ファイルの期間ごとに課金されます。 各チャネルを多重化して 1 つのファイルを送信すると、1 つのファイルの期間に対して課金されます。 価格の詳細については、[Azure Cognitive Services の価格のページ](https://azure.microsoft.com/pricing/details/cognitive-services/speech-services/)を参照してください。

> [!IMPORTANT]
> Custom Speech Service の使用について他にプライバシーに関する懸念がある場合は、いずれかのサポート チャネルにお問い合わせください。

## <a name="increasing-concurrency"></a>コンカレンシーの向上
「[Speech Services のクォータと制限](speech-services-quotas-and-limits.md)」を参照してください。


## <a name="importing-data"></a>データのインポート

**Q:データセットのサイズの制限とは何ですか、なぜ制限するのですか。**

**A**: この制限は、HTTP のアップロード用のファイルのサイズに対する制限が原因です。 実際の制限については、「[Speech Services のクォータと制限](speech-services-quotas-and-limits.md)」を参照してください。 データを複数のデータセットに分割し、すべてを選択してモデルをトレーニングすることができます。

**Q:テキスト ファイルを zip で圧縮すればさらに大きなテキスト ファイルをアップロードできるでしょうか。**

**A**: いいえ。 現時点では圧縮されていないテキスト ファイルのみが許可されます。

**Q:データ レポートが発話にエラーがあったと示しています。どのような問題が発生していますか。** "

**A**: ファイル内の発話の 100% をアップロードできなくても問題ありません。 音響または言語データセット内の発話の大多数 (95% 以上など) が正常にインポートされた場合、そのデータセットは使用可能と見なされます。 ただし、発話でエラーが発生した原因を理解してその問題を修正するよう試行することをお勧めします。 フォーマット エラーなどの一般的な問題は簡単に修正できます。

## <a name="creating-an-acoustic-model"></a>音響モデルの作成

**Q:どれくらいの量の音響データが必要ですか。**

**A**: 30 分から 1 時間分の音響データとの間で始まることをお勧めします。

**Q:どのようなデータを収集したほうがよいですか。**

**A**: できるだけアプリケーションのシナリオやユースケースに近いデータを収集してください。 データ コレクションはデバイス、環境、話者の種類の点でターゲット アプリケーションやユーザーと一致している必要があります。 一般的に、できるだけ広範囲の話者からデータを収集することをお勧めします。

**Q:音響データはどのように収集しますか。**

**A**: スタンドアロンのデータ コレクション アプリケーションを作成するか、既製の録音ソフトウェアを使用できます。 また、オーディオ データを記録してそれを使用するバージョンのアプリケーションを作成することもできます。

**Q:適応データを自分で文字に起こす必要はありますか。**

**A**: はい。 ご自身で文字に起こすか、プロの文字起こしサービスを利用してください。 プロの筆記者を好むユーザーもいれば、クラウドソーシングを使用したり、または自分で文字起こししたりするユーザーもいます。

**Q:オーディオ データを使用したカスタム モデルのトレーニングにはどのくらいの時間がかかりますか。**

**A**: オーディオ データを使用したモデルのトレーニングには、時間がかかる可能性があります。 データの量によっては、カスタム モデルの作成に数日かかる場合があります。 1 週間以内に完了できない場合、サービスはトレーニング操作を中止し、モデルを失敗として報告することがあります。

トレーニングに専用のハードウェアを使用できる[リージョン](custom-speech-overview.md#set-up-your-azure-account)のいずれかを使用します。 これらのリージョンでは、音声サービスのトレーニングのために最大 20 時間分の音声が使用されます。 他のリージョンでは、最大 8 時間のみが使用されます。

一般に、専用ハードウェアが導入されているリージョンでは、1 日あたり約 10 時間のオーディオ データが処理されています。 他のリージョンでは、1 日当たり 1 時間程度のオーディオ データしか処理できません。 [REST API](https://centralus.dev.cognitive.microsoft.com/docs/services/speech-to-text-api-v3-0/operations/CopyModelToSubscription) を使用して、完全にトレーニングされたモデルを別のリージョンにコピーできます。 テキストだけでトレーニングを行う方がはるかに高速で、通常は数分で完了します。

一部の基本モデルは、オーディオ データを使用してカスタマイズすることができません。 それらでは、サービスはトレーニングのために文字起こしのテキストのみを使用し、オーディオ データは無視します。 このとき、トレーニングがはるかに高速に完了し、テキストだけのトレーニングと同じ結果になります。 オーディオ データを使用したトレーニングをサポートする基本モデルの一覧については、「[言語のサポート](language-support.md#speech-to-text)」を参照してください。

## <a name="accuracy-testing"></a>正確性のテスト

**Q:ワード エラー率 (WER) とは何ですか。また、どのように計算されますか。**

**A**: WER は、音声認識の評価メトリックです。 WER はエラー (挿入、削除、置換など) の合計数から、参照する文字起こしの合計ワード数を除算して計算されます。 詳細については、「[Custom Speech の正確性を評価する](how-to-custom-speech-evaluate-data.md#evaluate-custom-speech-accuracy)」を参照してください。

**Q:正確性テストの結果が良好であることはどのように判断すればよいですか。**

**A**: 結果はベースライン モデルとカスタマイズしたモデルの比較を示します。 カスタマイズをそれだけの価値があるものにするには、ベースライン モデルを上回ることを目標にすべきです。

**Q:改善があったかどうかを知るためにベース モデルの WER はどのように確認できますか。**

**A**: オフライン テストの結果は、カスタム モデルのベースライン精度、およびベースラインからの改善を示します。

## <a name="creating-a-language-model"></a>言語モデルの作成

**Q:アップロードする必要があるテキスト データの量はどれくらいですか。**

**A**: アプリケーションで使用されているボキャブラリやフレーズが最初の言語モデルとどれくらい異なるかによって変わります。 すべての新しいワードについて、それらのワードの使用法の例をできるだけ多く提供すると便利です。 アプリケーションに使用されている一般的なフレーズについては、言語データにフレーズを含めると、システムにそれらの用語もリッスンするよう伝えるため、便利です。 言語データセットには最低でも 100、通常は数百以上の発話があることが一般的です。 また、ある種類 のクエリが他よりも一般的である場合、その一般的なクエリの複数のコピーをデータセットに挿入できます。

**Q:単語のリストをアップロードできますか。**

**A**: 単語のリストをアップロードすると、それらの単語はボキャブラリに追加されますが、それらの単語の一般的な使用方法はシステムに伝わりません。 すべての発話または発話の一部 (ユーザーが言いそうな文や語句) を指定すると、言語モデルはその新しい単語とその使用方法を学習します。 カスタム言語モデルは、システムに新しい単語を追加するだけでなく、新しいアプリケーションに対して既知の単語の確度を調整するのに便利です。 すべての発話を指定すると、システムがより学習できるようになります。

## <a name="tenant-model-custom-speech-with-microsoft-365-data"></a>テナント モデル (Microsoft 365 データを使用した Custom Speech)

**Q:テナント モデルに含まれている情報と、その作成方法を教えてください。**

**A:** テナント モデルは、組織内の誰でも見ることができる [パブリック グループ](https://support.microsoft.com/office/learn-about-microsoft-365-groups-b565caa1-5c40-40ef-9915-60fdb2d97fa2)のメールとドキュメントを使用して構築されます。

**Q:テナント モデルでは、どのような音声エクスペリエンスが向上しますか。**

**A:** テナント モデルを有効にし、作成して発行すると、Speech サービスを使用して構築されたエンタープライズ アプリケーションの認識を改善するために使用されます。また、企業へのメンバーシップを示すユーザーの Azure AD トークンも渡されます。

音声サービス アプリケーションのテナント モデルを作成しても、Microsoft 365 に組み込まれている音声エクスペリエンス (ディクテーションや PowerPoint キャプションなど) は変更されません。

## <a name="next-steps"></a>次のステップ

- [トラブルシューティング](troubleshooting.md)
- [リリース ノート](releasenotes.md)