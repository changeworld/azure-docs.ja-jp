---
title: Mapping data flow のパフォーマンスとチューニング ガイド
description: Azure Data Factory でのマッピング データ フローのパフォーマンスに影響する主な要因について説明します。
author: kromerm
ms.topic: conceptual
ms.author: makromer
ms.service: data-factory
ms.custom: seo-lt-2019
ms.date: 12/19/2019
ms.openlocfilehash: 3036fb44cdd636c4a7b9e690ee19aa3d5ab2f5ac
ms.sourcegitcommit: f4f626d6e92174086c530ed9bf3ccbe058639081
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 12/25/2019
ms.locfileid: "75444523"
---
# <a name="mapping-data-flows-performance-and-tuning-guide"></a>Mapping Data Flow のパフォーマンスとチューニング ガイド

Azure Data Factory の Mapping Data Flow には、大規模なデータ変換の設計、デプロイ、および調整するためのコード不要のインターフェイスが用意されています。 マッピング データ フローに慣れていない場合は、[マッピング データ フローの概要](concepts-data-flow-overview.md)に関するページを参照してください。

ADF UX から Data Flow の設計およびテストをする場合は、クラスターのウォーム アップを待機することなく、リアルタイムでデータ フローを実行するように、必ずデバッグ モードをオンにします。 詳細については、[デバッグ モード](concepts-data-flow-debug-mode.md)に関するページを参照してください。

## <a name="monitoring-data-flow-performance"></a>データ フローのパフォーマンスを監視する

Mapping Data Flow を設計する際に、[構成] パネルの [データ プレビュー] タブをクリックして、変換ごとに単体テストを行うことができます。 ロジックを確認したら、パイプラインでアクティビティとしてデータ フローをエンドツーエンドでテストします。 データ フローの実行アクティビティを追加し、[デバッグ] ボタンを使用して、データ フローのパフォーマンスをテストします。 データ フローの実行プランとパフォーマンス プロファイルを開くには、パイプラインの [出力] タブの [アクション] の下にある眼鏡アイコンをクリックします。

![データ フローの監視](media/data-flow/mon002.png "データ フローの監視 2")

 この情報を使用して、サイズの異なるデータ ソースに対するデータ フローのパフォーマンスを見積もることができます。 詳細については、[マッピング データ フローの監視](concepts-data-flow-monitoring.md)に関するページを参照してください。

![データ フローの監視](media/data-flow/mon003.png "データ フローの監視 3")

 パイプラインのデバッグを実行する場合、全体的なパフォーマンスの計算において、ウォーム クラスターのために約 1 分のクラスターの設定時間が必要です。 既定の Azure Integration Runtime を初期化する場合、起動時間に 5 分ほどかかる場合があります。

## <a name="increasing-compute-size-in-azure-integration-runtime"></a>Azure Integration Runtime でコンピューティング サイズを増やす

Integration Runtime でコア数を増やすと、Spark コンピューティング環境内のノード数が増加し、データの読み取り、書き込み、変換のための処理能力が向上します。
* 処理速度を入力速度より高くしたい場合は、**コンピューティング最適化**クラスターを試してください。
* メモリにより多くのデータをキャッシュしたい場合は、**メモリ最適化**クラスターを試してください。

![新しい IR](media/data-flow/ir-new.png "新しい IR")

Integration Runtime の作成方法の詳細については、「[Azure Data Factory の統合ランタイム](concepts-integration-runtime.md)」を参照してください。

### <a name="increase-the-size-of-your-debug-cluster"></a>デバッグ クラスターのサイズを増やす

既定では、デバッグを有効にすると、各データファクトリに対して自動的に作成される既定の Azure Integration Runtime が使用されます。 この既定の Azure IR は、一般コンピューティング プロパティを使用して、8 コア (ドライバー ノード用に 4、ワーカー ノード用に 4) に設定されています。 大きなデータを使用してテストする場合は、より大きな構成で Azure IR を作成することによってデバッグ クラスターのサイズを大きくし、デバッグ時に切り替えるときにこの新しい Azure IR を選択することができます。 これにより、データ フローを使用したデータ プレビューとパイプライン デバッグにこの Azure IR を使用するように、ADF に指示されます。

## <a name="optimizing-for-azure-sql-database-and-azure-sql-data-warehouse"></a>Azure SQL Database と Azure SQL Data Warehouse の最適化

### <a name="partitioning-on-source"></a>ソースでのパーティション分割

1. **[最適化]** タブに移動し、 **[Set Partitioning]\(パーティションの設定\)** を選択します。
1. **[ソース]** を選択します。
1. **[パーティションの数]** の下で、Azure SQL DB への最大接続数を設定します。 データベースへの並列接続を取得するために高い数値の設定を試すことができます。 ただし、場合によっては、接続の数を制限することでパフォーマンスが高速になることもあります。
1. 特定のテーブル列またはクエリでパーティション分割するかどうかを選択します。
1. **[列]** を選択した場合は、パーティション列を選択します。
1. **[クエリ]** を選択した場合は、データベース テーブルのパーティション構成に一致するクエリを入力します。 このクエリにより、ソース データベース エンジンがパーティション削除を利用できるようになります。 ソース データベース テーブルをパーティション分割する必要はありません。 ソースがまだパーティション分割されていない場合でも、ADF では、ソース変換でユーザーが選択したキーに基づいて、Spark 変換環境でデータのパーティション分割が使用されます。

![ソース パーツ](media/data-flow/sourcepart3.png "ソース パーツ")

### <a name="source-batch-size-input-and-isolation-level"></a>ソース バッチ サイズ、入力、および分離レベル

ソース変換の **[ソース オプション]** の下の次の設定がパフォーマンスに影響する可能性があります。

* バッチ サイズは、行単位ではなくメモリにセットでデータを格納するように ADF に指示します。 バッチ サイズは省略可能な設定で、適切にサイズを設定しないと、計算ノード上のリソースが不足する場合があります。
* クエリを設定すると、Data Flow に到達する前にソースで行をフィルター処理してから、処理することができます。 これにより、初期データの取得がより高速になります。 クエリを使用する場合は、READ UNCOMMITTED など、省略可能なクエリ ヒントを Azure SQL DB に追加することができます。
* [コミットされていないものを読み取り] は、ソース変換に関するより高速なクエリ結果を提供します。

![ソース](media/data-flow/source4.png "source")

### <a name="sink-batch-size"></a>シンクのバッチ サイズ

データ フローの行単位の処理を回避するには、Azure SQL DB と Azure SQL DW のシンクの [設定] タブで **[バッチ サイズ]** を設定します。 バッチ サイズが設定されると、ADF では指定されたサイズに基づいて、データベースの書き込みがバッチで処理されます。

![シンク](media/data-flow/sink4.png "シンク")

### <a name="partitioning-on-sink"></a>シンクでのパーティション分割

ターゲットのテーブルでデータがパーティション分割されていない場合でも、シンク変換でデータをパーティション分割することをお勧めします。 多くの場合、パーティション分割されたデータは、すべての接続で単一のノード/パーティションを使用するように強制するよりも、ずっと高速に読み込むことができます。 シンクの [最適化] タブにアクセスし、 *[ラウンド ロビン]* パーティション分割を選択して、シンクに書き込む最適なパーティション数を選択します。

### <a name="disable-indexes-on-write"></a>書き込み時にインデックスを無効にする

パイプラインで、シンクからの書き込み先のターゲット テーブルでインデックスを無効にする Data Flow アクティビティの前に、[ストアド プロシージャ アクティビティ](transform-data-using-stored-procedure.md)を追加します。 Data Flow アクティビティの後に、これらのインデックスを有効にする別のストアド プロシージャ アクティビティを追加します。 または、データベース シンクで処理前および処理後のスクリプトを使用します。

### <a name="increase-the-size-of-your-azure-sql-db-and-dw"></a>Azure SQL DB と DW のサイズを増やす

DTU の制限に達したら、ソースとシンクの Azure SQL DB と DW のサイズ変更をスケジュールしてから、パイプラインを実行して、スループットを増やし、Azure スロットルを最小化します。 パイプラインの実行が完了したら、データベースのサイズを変更して通常のラン レートに戻します。

### <a name="azure-sql-dw-only-use-staging-to-load-data-in-bulk-via-polybase"></a>[Azure SQL DW のみ] ステージングを使用して、Polybase を介してデータを一括で読み込む

DW への行単位の挿入を回避するには、シンク設定で **[Enable Staging]\(ステージングの有効化\)** をオンにして、ADF で [PolyBase](https://docs.microsoft.com/sql/relational-databases/polybase/polybase-guide) を使用できるようにします。 PolyBase を使用すると、ADF はデータを一括で読み込むことができます。
* パイプラインからデータ フロー アクティビティを実行する場合は、一括読み込み中にデータをステージングするために、BLOB または ADLS Gen2 ストレージの場所を選択する必要があります。

## <a name="optimizing-for-files"></a>ファイルのための最適化

変換ごとに、データ ファクトリで使用するパーティション構成を [最適化] タブで設定できます。
* 小さいファイルの場合は、 *[単一パーティション]* を選択すると、小さいファイルをパーティション分割するように Spark に要求するよりも効果的で速い場合があります。
* ソース データに関する十分な情報がない場合は、 *[ラウンド ロビン]* パーティション分割を選択して、パーティションの数を設定します。
* データに適切なハッシュ キーになる列が含まれている場合は、 *[ハッシュ パーティション分割]* を選択します。

データ プレビューおよびパイプライン デバッグでデバッグする場合、ファイルベースのソース データセットの制限とサンプリングのサイズは、読み取られる行数ではなく、返される行数にのみ適用されます。 これは、ご自身のデバッグの実行のパフォーマンスに影響を与え、場合によってはフローが失敗する可能性があります。
* デバッグ クラスターは既定では小規模な単一ノードのクラスターであるため、デバッグにはサンプルの小さいファイルを使用することをお勧めします。 [Debug Settings]\(デバッグ設定\) にアクセスし、一時ファイルを使用しているお使いのデータの小さなサブセットをポイントします。

    ![デバッグ設定](media/data-flow/debugsettings3.png "デバッグ設定")

### <a name="file-naming-options"></a>ファイルの名前付けのオプション

マッピング データ フローで変換されたデータを書き込む最も一般的な方法は、BLOB または ADLS ファイル ストアに書き込むことです。 シンクでは、名前付きファイルではなく、コンテナーまたはフォルダーをポイントするデータセットを選択する必要があります。 マッピング データ フローでは、実行に Spark が使用されるため、出力はご使用のパーティション構成に基づいて複数のファイルに分割されます。

一般的なパーティション構成では、 _[単一ファイルへの出力]_ を選択します。これによりすべての出力 PART ファイルがシンク内の 1 つのファイルにマージされます。 この操作では、出力を単一のクラスター ノード上の単一のパーティションに減らす必要があります。 多数の大きなソース ファイルを単一の出力ファイルに結合する場合、クラスター ノードのリソースが不足することがあります。

計算ノードのリソースの枯渇を回避するには、データ フローの既定の最適化されたスキームを維持し、すべての PART ファイルを出力フォルダーから単一の新しいファイルにマージするコピー アクティビティをパイプラインに追加します。 この手法は、変換の動作をファイルのマージから切り離し、_単一ファイルへの出力_を設定するのと同じ結果が得られます。

### <a name="looping-through-file-lists"></a>ファイル リストのループ処理

ソース変換が For Each アクティビティを通じてループするのではなく、複数のファイルを反復処理する場合、マッピング データ フローの方が実行効率に優れています。 ソース変換では、ワイルドカードまたはファイル リストを使用することをお勧めします。 ループ処理を Spark クラスター内で行うことにより、Data Flow プロセスの実行速度を上げることができます。 詳細については、[ソース変換でのワイルドカード](connector-azure-data-lake-storage.md#mapping-data-flow-properties)に関するセクションを参照してください。

たとえば、2019 年 7 月のデータ ファイルの一覧を Blob Storage のフォルダーで処理する場合は、ソース変換で次のワイルドカードを使用できます。

```DateFiles/*_201907*.txt```

ワイルドカードを使用すると、パイプラインには 1 つの Data Flow アクティビティだけが含まれます。 BLOB ストアを検索し、ForEach を使用して、その内側で Data Flow の実行アクティビティを使用しながら、一致するすべてのファイルを反復処理させるよりも、この方が効率がよくなります。

### <a name="optimizing-for-cosmosdb"></a>CosmosDB のための最適化

CosmosDB シンクのスループットとバッチ プロパティの設定は、パイプライン データ フロー アクティビティからのそのデータ フローの実行中にのみ有効になります。 元のコレクションの設定は、データ フローの実行後に CosmosDB によって受け入れられます。

* バッチ サイズ: データの行のおおよそのサイズを計算し、rowSize * バッチサイズが 200 万未満であることを確認します。 その場合は、バッチ サイズを増やしてスループットを向上させます。
* スループット: ここでより高いスループットを設定して、CosmosDB にドキュメントを高速で書き込むことができるようにします。 高いスループットの設定に基づいて、RU コストが高くなることに注意してください。
*   書き込みスループット予算:1 分あたりの RU の合計よりも小さい値を使用してください。 多数の Spark パーティションが含まれるデータ フローがある場合、予算のスループットを設定すると、これらのパーティション間でより均等にバランスを取ることができます。

## <a name="next-steps"></a>次のステップ

パフォーマンスに関する Data Flow のその他の記事を参照してください。

- [データ フローの [最適化] タブ](concepts-data-flow-overview.md#optimize)
- [Data Flow のアクティビティ](control-flow-execute-data-flow-activity.md)
- [データ フローのパフォーマンスの監視](concepts-data-flow-monitoring.md)
