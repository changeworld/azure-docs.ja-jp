---
title: 組み込みのインデクサーを使用して大容量のデータ セットのインデックスを作成する
titleSuffix: Azure Cognitive Search
description: 大容量データのインデックス作成またはバッチ モードでの計算負荷の高いインデックス作成の戦略と、リソース管理と、スケジュール設定されたインデックス作成、並列インデックス作成、および分散インデックス作成のためのテクニック。
manager: liamca
author: dereklegenzoff
ms.author: delegenz
ms.service: cognitive-search
ms.topic: conceptual
ms.date: 05/05/2020
ms.openlocfilehash: 915243fb4dbc6bb274e26261bc5741811ef24592
ms.sourcegitcommit: a6d477eb3cb9faebb15ed1bf7334ed0611c72053
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 05/08/2020
ms.locfileid: "82925985"
---
# <a name="how-to-index-large-data-sets-in-azure-cognitive-search"></a>Azure Cognitive Search で大容量のデータ セットのインデックスを作成する方法

Azure Cognitive Search は、検索インデックスにデータをインポートする [2 つの基本的な手法](search-what-is-data-import.md)をサポートしています。1 つは、プログラムを使用してインデックスにデータを "*プッシュ*" する方法、もう 1 つは、サポート対象データ ソースで [Azure Cognitive Search のインデクサー](search-indexer-overview.md)をポイントしてデータを "*プル*" する方法です。

データ量が増加した場合や処理の変更が必要になった場合、単純な、または既定のインデックス作成戦略では、もはや十分でないことに気付くことがあります。 Azure Cognitive Search の場合、大容量のデータ セットに対応するための方法がいくつかあります。それは、データ アップロード要求を構造化する方法から、スケジュール設定され分散されたワークロードに対してソース固有のインデクサーを使用する方法までさまざまです。

実行時間の長いプロセスにも同じ手法が適用されます。 具体的には、「[並列インデックス作成](#parallel-indexing)」で説明する手順は、[AI エンリッチメント パイプライン](cognitive-search-concept-intro.md)での画像分析や自然言語処理など、計算負荷の高いインデックス作成に役立ちます。

以降のセクションでは、Push API とインデクサーの両方を使用して大量のデータのインデックスを作成する方法について説明します。

## <a name="push-api"></a>Push API

インデックスにデータをプッシュするとき、Push API に対するインデックスの作成速度を左右するいくつかの重要な考慮事項があります。 これらの要因については、以下のセクションで説明します。 

この記事の情報に加えて、[インデックス作成速度を最適化するチュートリアル](tutorial-optimize-indexing-push-api.md)のコード サンプルを利用すると、より深く学習することができます。

### <a name="service-tier-and-number-of-partitionsreplicas"></a>サービス レベルとパーティションまたはレプリカの数

パーティションを追加したり、検索サービスのサービス レベルを増やしたりすると、インデックス作成速度が向上します。

レプリカを追加してもインデックス作成速度が向上する可能性はありますが、これは保証されません。 一方、レプリカを追加すると、検索サービスが処理できるクエリの量が増加します。 レプリカは、[SLA](https://azure.microsoft.com/support/legal/sla/search/v1_0/) を取得するための重要なコンポーネントでもあります。

パーティションまたはレプリカを追加する前、または上位のレベルにアップグレードする前に、金銭的コストと割り当て時間を検討してください。 パーティションを追加すると、インデックス作成速度が大幅に向上しますが、それらを追加または削除するには、15 分から数時間かかることがあります。 詳細については、[容量調整](search-capacity-planning.md)に関するドキュメントを参照してください。

### <a name="index-schema"></a>インデックス スキーマ

インデックスのスキーマは、データのインデックス作成において重要な役割を果たします。 フィールドを追加したり、フィールドに別のプロパティ (*searchable*、*facetable*、*filterable* など) を追加したりすると、インデックスの作成速度が落ちます。

一般に、フィールドにプロパティを追加するのは、それを使用する予定がある場合にのみ行うことをお勧めします。

> [!NOTE]
> ドキュメントのサイズが大きくならないように、クエリできないデータをインデックスに追加しないようにします。 イメージとその他のバイナリ データは直接検索できないため、インデックスには格納しないでください。 クエリ不可能なデータを検索結果に含めるには、リソースへの URL 参照を格納する検索不可能なフィールドを定義してください。

### <a name="batch-size"></a>バッチ サイズ

大容量のデータ セットにインデックスを付けるための最も簡単なメカニズムの 1 つは、複数のドキュメントまたはレコードを 1 つの要求で送信するというものです。 ペイロード全体が 16 MB を超えない限り、1 つの要求によって、一括アップロード操作で最大 1000 のドキュメントを処理できます。 .NET SDK で [Add Documents REST API](https://docs.microsoft.com/rest/api/searchservice/addupdate-or-delete-documents) と [Index メソッド](https://docs.microsoft.com/dotnet/api/microsoft.azure.search.documentsoperationsextensions.index?view=azure-dotnet)のどちらを使用しているかによって、これらの制限が適用されます。 どちらの API でも、各要求の本文に 1,000 個のドキュメントをパッケージ化します。

バッチを使用してドキュメントにインデックスを付けると、インデックス作成のパフォーマンスが大幅に向上します。 実際のデータに最適なバッチ サイズを見極めることが、インデックスの作成速度を最適化するうえで重要な要素となります。 最適なバッチ サイズは主に、次の 2 つの要因によって左右されます。
+ インデックスのスキーマ
+ データのサイズ

最適なバッチ サイズはインデックスとデータによって異なるため、さまざまなバッチ サイズをテストしながら、実際のシナリオにおいてインデックスの作成速度が最速となるサイズを見極めるのが最善のアプローチとなります。 この[チュートリアル](tutorial-optimize-indexing-push-api.md)では、.NET SDK を使用してバッチ サイズをテストするためのサンプル コードを提供しています。 

### <a name="number-of-threadsworkers"></a>スレッドまたは worker の数

Azure Cognitive Search のインデックス作成速度を最大限に引き出すには、おそらく複数のスレッドを使用して、インデックス作成要求のバッチをサービスに対して同時に送信する必要があります。  

最適なスレッド数は次の方法で決定されます。

+ 検索サービスのサービス レベル
+ パーティションの数
+ バッチのサイズ
+ インデックスのスキーマ

さまざまなスレッド数でこのサンプルを変更、テストすることによって、実際のシナリオに最適なスレッド数を見極めてください。 ただし、複数のスレッドを同時に実行すれば、効率向上の利点はおおよそ活かすことができるはずです。 

> [!NOTE]
> 検索サービスのレベルを上げたり、パーティションを増やしたりする場合は、同時実行スレッドの数も増やす必要があります。

検索サービスに対する要求を増やしていくと、要求が完全には成功しなかったことを示す [HTTP 状態コード](https://docs.microsoft.com/rest/api/searchservice/http-status-codes)が返されることがあります。 インデックスの作成時によく発生する HTTP 状態コードは次の 2 つです。

+ **503 Service Unavailable** - このエラーは、システムが過負荷の状態にあり、この時点では要求を処理できないことを示します。
+ **207 Multi-Status** - このエラーは、ドキュメントの一部は成功しましたが、少なくとも 1 つが失敗したことを示します。

### <a name="retry-strategy"></a>再試行戦略 

失敗した要求は、[エクスポネンシャル バックオフの再試行戦略](https://docs.microsoft.com/dotnet/architecture/microservices/implement-resilient-applications/implement-retries-exponential-backoff)を使用して再試行する必要があります。

503 などで失敗した要求は、Azure Cognitive Search の .NET SDK によって自動的に再試行されますが、207 には、独自の再試行ロジックを実装する必要があります。 [Polly](https://github.com/App-vNext/Polly) などのオープンソース ツールを使用して、再試行戦略を実装することもできます。

### <a name="network-data-transfer-speeds"></a>ネットワーク データ転送速度

データのインデックスを作成する場合、ネットワーク データ転送速度が制限要因になる場合があります。 Azure 環境内からのデータのインデックス作成は、インデックス作成を高速化する簡単な方法です。

## <a name="indexers"></a>インデクサー

[インデクサー](search-indexer-overview.md)は、検索可能なコンテンツに対してサポートされている Azure データ ソースをクロールするために使用されます。 大規模なインデックス作成を特に目的としていなくても、いくつかのインデクサー機能は、より大きな容量のデータ セットに対応する上で特に便利です。

+ スケジューラを使用すると、インデックス作成を一定の間隔で配分して行い、時間をかけて徐々に行うことができます。
+ スケジュール済みのインデックス作成は、最後の既知の停止ポイントから再開することができます。 24 時間の範囲内でデータ ソースが完全にクロールされていない場合、中断されたところから 2 日目にインデクサーによってインデックス作成が再開されます。
+ データをより小さな個々のデータ ソースにパーティション分割することにより、並列処理が実現されます。 ソース データは、Azure BLOB ストレージ内の複数のコンテナーなど、より小さなコンポーネントに分割してから、対応する複数の[データ ソース オブジェクト](https://docs.microsoft.com/rest/api/searchservice/create-data-source)を Azure Cognitive Search で作成して、並列でインデックスを作成することができます。

> [!NOTE]
> インデクサーはデータ ソース固有のものです。そのため、インデクサー アプローチの使用は、Azure 上で選択される次のデータ ソースに対してのみ有効です。[SQL Database](search-howto-connecting-azure-sql-database-to-azure-search-using-indexers.md)、[Blob Storage](search-howto-indexing-azure-blob-storage.md)、[Table Storage](search-howto-indexing-azure-tables.md)、[Cosmos DB](search-howto-index-cosmosdb.md)。

### <a name="batch-size"></a>バッチ サイズ

Push API と同様に、インデクサーを使用すると、バッチごとに項目の数を構成できます。 [インデクサーの作成 (REST API)](https://docs.microsoft.com/rest/api/searchservice/Create-Indexer) に基づいたインデクサーの場合は、引数 `batchSize` を設定することで、ご利用のデータの特性に合わせてこの設定をカスタマイズすることができます。 

既定のバッチ サイズは、データ ソースによって異なります。 Azure SQL Database と Azure Cosmos DB の既定のバッチ サイズは 1000 です。 それに対して、Azure Blob インデックス作成では、より大きな平均ドキュメント サイズを認識して、バッチ サイズが 10 のドキュメントに設定されます。 

### <a name="scheduled-indexing"></a>スケジュール済みのインデックス作成

インデクサーのスケジュール設定は、大容量のデータ セットの処理や、コグニティブ検索パイプラインでの画像分析などの低速実行処理を行う上で重要なメカニズムです。 インデクサーの処理は、24 時間の範囲内で動作します。 24 時間以内に処理が完了しなかった場合、インデクサーのスケジュール機能が効果を発揮します。 

スケジュール機能付きインデックスは、特定の間隔で始動する設計になっており、通常は、ジョブが完了し、次回のスケジュール間隔で再開されます。 ただし、間隔内で処理が完了しない場合、インデクサーは (時間不足のため) 停止します。 処理がどこで停止したかがシステムに記録されており、次の間隔では、前回停止した個所から処理が再開されます。 

実際には、インデックスの読み込みに数日かかる場合、24 時間スケジュールでインデクサーを配置できます。 次の 24 時間サイクルでインデックス作成が再開すると、前回正常だったと認識されたドキュメントから再開されます。 このようにして、インデクサーは、すべての未処理ドキュメントが処理されるまで、ドキュメントのバックログに従って数日にわたり処理を続けます。 この方法の詳細については、[Azure Blob Storage での大容量のデータセットのインデックス作成](search-howto-indexing-azure-blob-storage.md#indexing-large-datasets)に関するページを参照してください。 一般的なスケジュール設定の詳細については、[インデクサーの作成 (REST API)](https://docs.microsoft.com/rest/api/searchservice/Create-Indexer) に関するページ、または [Azure Cognitive Search のインデクサーのスケジュールを設定する方法](search-howto-schedule-indexers.md)に関する記事を参照してください。

<a name="parallel-indexing"></a>

### <a name="parallel-indexing"></a>並列インデックス作成

並列インデックス作成戦略は、複数のデータ ソースのインデックスをまとめて作成する方法に基づいています。ここで、各データ ソース定義によってデータのサブセットが指定されます。 

ルーチン以外の計算負荷の高いインデックス作成要件の場合 (コグニティブ検索パイプライン、画像分析、または自然言語処理でスキャンされるドキュメント上での OCR など)、実行時間の長いプロセスを最短の時間で完了させるには、多くの場合、並列インデックス作成戦略が適切なアプローチです。 クエリ要求を排除または削減できる場合、クエリを同時に処理しないサービスでの並列インデックス作成は、処理に時間がかかるサイズの大きなコンテンツを処理するのに最善の戦略オプションとなります。 

並列処理は次の要素で構成されます。

+ 複数のコンテナーまたは同じコンテナー内の複数の仮想フォルダーにソース データを分割します。 
+ 各ミニ データ セットを、独自の[インデクサー](https://docs.microsoft.com/rest/api/searchservice/create-indexer)と対になった、独自の[日付ソース](https://docs.microsoft.com/rest/api/searchservice/create-data-source)にマッピングします。
+ コグニティブ検索の場合、各インデクサー定義で同じ[スキルセット](https://docs.microsoft.com/rest/api/searchservice/create-skillset)を参照します。
+ 同じターゲット検索インデックスに書き込みます。 
+ すべてのインデクサーが同時に実行されるよう、スケジュールを設定します。

> [!NOTE]
> Azure Cognitive Search では、個々のレプリカやパーティションをインデックス作成やクエリ処理に割り当てることはできません。 システムがリソースの使用方法を決定します。 クエリのパフォーマンスへの影響を把握するには、実稼働環境に展開する前に、テスト環境で並列インデックス作成を試してください。  

### <a name="how-to-configure-parallel-indexing"></a>並列インデックス作成の構成方法

インデクサーの処理容量は、検索サービスによって使用される各サービス ユニット (SU) の 1 つのインデクサー サブシステムを基に概算されます。 2 つ以上のレプリカがある Basic または Standard レベルにプロビジョニングされている Azure Cognitive Search サービス上では、複数の並列インデクサーが可能です。 

1. [Azure Portal](https://portal.azure.com) の、検索サービス ダッシュ ボードの **[概要]** ページにある、 **[価格レベル]** で並列インデックスに対応できることを確認してください。 Basic および Standard の両方のレベルで、複数のレプリカが提供されています。

2. **[設定]**  >  **[スケール]** で並列処理の[レプリカを増やし](search-capacity-planning.md)ます。インデクサー ワークロードごとに 1 つ追加します。 既存のクエリ量は十分な数に設定します。 インデックス作成のためのクエリ ワークロードを犠牲にすることは、適切なトレードオフではありません。

3. Azure Cognitive Search インデクサーが到達可能なレベルの複数のコンテナーにデータを分割します。 これには、Azure SQL Database 内の複数のテーブル、Azure BLOB ストレージ内の複数のコンテナー、または複数のコレクションが考えられます。 テーブルまたはコンテナーごとに 1 つのデータ ソース オブジェクトを定義します。

4. 並列実行する複数のインデクサーを作成し、スケジュールを設定します。

   + 1 つのサービスに 6 つのレプリカを作成するとします。 データ セット全体を 6 つに分割するには、6 つのインデクサーを作成し、そのそれぞれを 6 分の 1 のデータ セットを含むデータ ソースに割り当てるよう構成します。 

   + 各インデクサーが同じインデックスを参照するよう設定します。 コグニティブ検索ワークロードの場合は、各インデクサーが同じスキルセットを参照するよう設定します。

   + 各インデクサーの定義で、同じランタイム実行パターンをスケジュールします。 たとえば、`"schedule" : { "interval" : "PT8H", "startTime" : "2018-05-15T00:00:00Z" }` は、8 時間間隔ですべてのインデクサーが 2018 年 5 月 15 日に実行されるスケジュールを作成します。

予定された時刻に、すべてのインデクサーの実行が開始され、データが読み込まれ、エンリッチメント (認知検索パイプラインを構成した場合) が適用され、インデックスに書き込まれます。 Azure Cognitive Search では、更新中のインデックスはロックされません。 同時書き込みは、特定の書き込みが最初の試行に成功しなかった場合、再試行することで管理されます。

> [!Note]
> レプリカを増やす際、インデックスのサイズが大幅に増加することが予想される場合は、パーティション数を増やすことを検討してください。 パーティションにはインデックスのコンテンツのスライスが格納され、パーティション数が多いほど、各パーティションに格納されるスライスも小さくなります。

## <a name="see-also"></a>関連項目

+ [インデクサーの概要](search-indexer-overview.md)
+ [ポータル内でのインデックス作成](search-import-data-portal.md)
+ [Azure SQL Database インデクサー](search-howto-connecting-azure-sql-database-to-azure-search-using-indexers.md)
+ [Azure Cosmos DB インデクサー](search-howto-index-cosmosdb.md)
+ [Azure Blob Storage インデクサー](search-howto-indexing-azure-blob-storage.md)
+ [Azure Table Storage インデクサー](search-howto-indexing-azure-tables.md)
+ [Azure Cognitive Search のセキュリティ](search-security-overview.md)
