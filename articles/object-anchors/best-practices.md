---
title: 推奨する運用方法
description: 改善された結果を得るための推奨されるベスト プラクティス
author: ariye
ms.author: crtreasu
ms.date: 03/12/2021
ms.topic: best-practice
ms.service: azure-object-anchors
ms.openlocfilehash: e287d8305b3fd85fc992417e1563b1e58e6f8424
ms.sourcegitcommit: 772eb9c6684dd4864e0ba507945a83e48b8c16f0
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/20/2021
ms.locfileid: "103463002"
---
# <a name="best-practices"></a>ベスト プラクティス

最良の結果を得るために、これらの手順のいくつかを試してみることをお勧めします。

## <a name="ingestion"></a>データの取り込み

- 物理オブジェクトのディメンションを確認します。 Azure Object Anchors は、最小ディメンションが、推奨されている 1 m から 10 m の範囲内のオブジェクトで最もうまく機能します。
- [**MeshLab**](https://www.meshlab.net/) のようなソフトウェアで 3D モデルを調べて、次の詳細を確認します。
  - 3D モデルに三角形のメッシュがあること、および外部サーフェス上の三角形が外側を向いていることを確認します。 つまり、頂点の向きが、法線が外の向きにおいて右手の法則に従うようになっている必要があります。
  - 3D モデルが、物理オブジェクトに対して適切なスケール ユニットで指定されていることを確認します。 ユニットは、"***センチメートル、デシメートル、フィート、インチ、キロメートル、メートル、ミリメートル、ヤード***" のいずれかである必要があります。
  - オブジェクトの実際の垂直方向に対応する公称の重力方向を確認します。 オブジェクトの下向きの垂直または重力が -Y の場合は、* **(0, -1, 0)** _ または _*_ (0, 0, -1)_** を -Z に使用します。その他の方向についても同様です。
  - 3D モデルが `.glb`、`.gltf`、`.ply`、`.fbx`、`.obj` のいずれかのサポートされた形式でエンコードされていることを確認します。
- このモデル変換サービスでは、サイズが大きく、LOD (詳細レベル) が高いモデルの処理には時間がかかることがあります。 効率を高めるために、3D モデルを前処理して内部の面を削除できます。

## <a name="detection"></a>検出

> [!VIDEO https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Azure-Object-Anchors-Detection-and-Alignment-Best-Practices/player]

- 提供されているランタイム SDK には、物理オブジェクトを検索して検出するために、ユーザー指定の検索領域が必要です。 検索領域は、境界ボックス、球、視錐台、またはそれらを組み合わせたものにすることができます。 誤検出を回避するために、オブジェクトをカバーするのに十分な大きさの検索領域を設定することをお勧めします。 提供されているサンプル アプリを使用するときは、最も近いサーフェスから約 2 メートル離れたところにオブジェクトの片側が来るところに立って、アプリを起動できます。
- HoloLens 2 デバイスで Azure Object Anchors アプリを開始する前に、デバイスのメイン設定から、***[設定] -> [システム] -> [ホログラム]*** を使用して、自分のワークプレースの近くにあるホログラムを削除します。

  この手順を実行することで、自動車などの新しいオブジェクトが、以前別のものに占有されていた同じ空間に存在する場合や、オブジェクトがターゲット空間から移動された場合に、関係のない古いホログラムが永続化され、現在ビューに含まれているオブジェクトの視覚化で混乱が生じないようにすることができます。
- ホログラムを削除したら、アプリを起動する前に、約 1、2 メートルのところからデバイスを装着した状態でオブジェクトを見て、オブジェクトの周りをゆっくりと 1、2 回まわることによって、自動車などのオブジェクトをスキャンします。

  この手順を実行することで、以前のオブジェクトとスキャンによって領域内に作成された残留するサーフェスの推定値が、これから操作する現在のターゲット オブジェクトのサーフェスによって確実に更新されます。 そうしないと、アプリが 2 つのゴースト サーフェスを認識し、3D モデルと、関連するホログラムが正しく配置されない可能性があります。 オブジェクトを事前にスキャンすることで、Azure Object Anchors 検出の待機時間も大幅に (30 秒から 5 秒) 短縮されます。
- 暗色や高反射のオブジェクトの場合は、より近距離から、またデバイスに複数の角度と複数の距離からサーフェスを認識させるために頭を上下左右に動かしてオブジェクトをスキャンする必要がある場合があります。
- 向きが反転したり、モデルが傾いているなど姿勢が正しくなかったりして、物体検出が正しく行われていない場合は、空間マッピングを視覚化する必要があります。 多くの場合、誤った結果は、サーフェスの再構築が適切に行われていない、または不完全であることが原因です。 ホログラムを削除し、オブジェクトをスキャンし、アプリで物体検出を再実行できます。
- サンプル アプリに示されているように、提供されているランタイム SDK には、ユーザーが検出を微調整するために使用できるいくつかのパラメーターが用意されています。 ほとんどのオブジェクトで既定のパラメーターが十分機能します。 特定のオブジェクト用に調整する必要がある場合は、次の推奨事項を参照してください。
  - 物理オブジェクトが大きい、暗色である、または光沢がある場合は、低いサーフェス カバレッジしきい値を使用します。
  - 自動車のような大きなオブジェクトでは、小さなスケール変更 (0.1 など) を考慮します。
  - オブジェクトが傾斜地にあるときは、オブジェクトのローカルの垂直方向と重力の間で度数に若干のずれが生じることを考慮します。
