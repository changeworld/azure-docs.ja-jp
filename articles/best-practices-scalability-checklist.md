<properties
   pageTitle="スケーラビリティのチェックリスト|Microsoft Azure"
   description="Azure 自動スケールの設計に関するスケーラビリティのチェックリスト ガイダンス。"
   services=""
   documentationCenter="na"
   authors="dragon119"
   manager="masimms"
   editor=""
   tags=""/>

<tags
   ms.service="best-practice"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="na"
   ms.date="03/26/2016"
   ms.author="masashin"/>

# スケーラビリティのチェックリスト

![](media/best-practices-scalability-checklist/pnp-logo.png)

## サービスの設計
- **ワークロードを分割します**。プロセスのパーツを別個に分解できるように設計します。また、処理内容の独立の一般規則および単一責任の法則に従って、各パーツのサイズは最小限にします。これにより、各コンピューティング ユニット (ロールやデータベース サーバーなど) を最大限に使用できるようにコンポーネントのパーツを分散できます。また、特定のリソースのインスタンスを追加することで、アプリケーションのスケーリングが容易になります。詳細については、「[Compute Partitioning Guidance (コンピューティング パーティション分割のガイダンス)](https://msdn.microsoft.com/library/dn589773.aspx)」を参照してください。
- **スケーリングを考慮して設計します**。スケーリングにより、アプリケーションは、ロール、キュー、および使用する他のサービスのインスタンスの数を増減することで、変動負荷に対応できます。ただし、アプリケーションを設計する際には、次の点を考慮に入れる必要があります。たとえば、アプリケーションとそれが使用するサービスはステートレスにして、要求をどのインスタンスにもルーティングできるようにする必要があります。また、特定のインスタンスの追加または削除によって、現行ユーザーに悪影響が及ばないようにします。さらに、インスタンスの追加または削除時にインスタンスの再構成や自動検出を行うしくみを実装して、アプリケーション内のコードが必要なルーティングを実行できるようにします。たとえば、Web アプリケーションは一連のキューをラウンド ロビン方式で使用して、worker ロールで実行しているバックグラウンド サービスに要求をルーティングする場合があります。Web アプリケーションは、要求を正しくルーティングして、アプリケーションへの負荷を均等にするために、キューの数の変更を検出できる必要があります。
- **ユニットとしてスケールします**。成長に合わせてリソースを追加するように計画します。リソースごとに、スケーリングの上限を確認し、シャーディングまたは分解を使用して、これらの限度を超える必要があります。明確に定義されたリソースのセットを単位として、システムのスケール ユニットを判別します。これにより、スケールアウト操作の適用が容易になるだけでなく、システム全体のある部分でリソースが不足しているために制限が課され、アプリケーションに悪影響を及ぼす可能性を避けることができます。たとえば、x 個の Web ロールおよび worker ロールを追加すると、それらのロールによって生成される追加のワークロードを処理するために、y 個の追加キューおよび z 個のストレージ アカウントが必要になる場合があります。このスケール ユニットは x 個の Web ロールおよび worker ロール、_y_ 個のキュー、_z_ 個のストレージ アカウントで構成できます。1 つ以上のスケール ユニットを追加することでスケーリングが容易になるように、アプリケーションを設計してください。
- **クライアント アフィニティを回避します**。可能であれば、アプリケーションがアフィニティを必要としていないことを確認します。こうすることで、どのインスタンスにも要求をルーティングでき、インスタンスの数に影響されずに済みます。これにより、各ユーザーの状態情報を格納、取得、保守するためのオーバーヘッドが生じることもなくなります。
- **プラットフォーム自動スケール機能を活用します**。ホスティング プラットフォームが Azure 自動スケールなどの自動スケール機能をサポートする場合は、組み込みのメカニズムで要求を満たせない場合を除き、カスタムまたはサードパーティのメカニズムではなく自動スケール機能を使用してください。可能な限り、スケジュールされたスケーリング ルールを使用し、起動時の遅延なしでリソースを使用可能にします。しかし、必要に応じてリアクティブ自動スケールをルールに追加し、予期しない要求の変化に対応する必要があります。Service Management API で自動スケール操作を使用して、自動スケールを微調整したり、カスタム カウンターをルールに追加したりできます。詳細については、「[自動スケール ガイダンス](best-practices-auto-scaling.md)」を参照してください。
- **負荷の高い CPU/IO タスクをバックグラウンド タスクとしてオフロードします**。サービスへの要求の実行に長時間かかったり、かなりのリソースを消費したりすることが予測される場合、この要求の処理を別個のタスクにオフロードします。(ホスティング プラットフォームに応じ、) worker ロールまたはバックグラウンド ジョブを使用して、これらのタスクを実行します。この戦略を使用すると、サービスはさらに多くの要求を引き続き受信したり、即座に対応したりすることが可能になります。詳細については、「[Background jobs guidance (バックグラウンド ジョブのガイダンス)](best-practices-background-jobs.md)」を参照してください。
- **バックグラウンド タスクのワークロードを分散します**。多くのバックグラウンド タスクがある場合、またはタスクの実行に相当の時間かリソースが必要な場合、複数のコンピューティング ユニット (worker ロールまたはバックグラウンド ジョブなど) に作業を分散します。考えられる解決策の 1 つについては、「[Competing Consumers Pattern (競合コンシューマー パターン)](https://msdn.microsoft.com/library/dn568101.aspx)」を参照してください。
- **_シェアード ナッシング_ アーキテクチャの使用を考慮します**。シェアード ナッシング アーキテクチャでは、ノードは独立し自律的で、単一競合箇所 (共有サービスや共有ストレージなど) がありません。理論上、そのようなシステムはほぼ無制限にスケールできます。一般に、完全なシェアード ナッシング アプローチはほとんどのアプリケーションで実用的ではありませんが、スケーラビリティの向上を考慮に入れた設計には適している場合があります。たとえば、サーバー側のセッション状態、クライアント アフィニティ、データのパーティション分割の使用を避けるという方法は、シェアード ナッシング アーキテクチャを使用する良い例です。

## データ管理

- **データのパーティション分割を使用します**。データを複数のデータベースおよびデータベース サーバーに分割するか、このパーティション分割を透過的に実行できるデータ ストレージ サービスを使用するようにアプリケーションを設計します (サービスの例として、Azure SQL Database Elastic Database や Azure Table Storage などがあります)。このアプローチを使用すると、パフォーマンスを最大化すると同時に、スケーリングを容易にすることが可能です。パーティション分割には、水平的、垂直的、機能的など、さまざまな分割法があります。これらを組み合わせて使用すると、クエリのパフォーマンスの向上、シンプル化されたスケーラビリティ、より柔軟性のある管理、可用性の向上から得られるメリットを最大限に活用できるだけでなく、保持されるデータとデータ ストアの種類を一致させることができます。さらに、データ タイプに応じて異なる種類のデータ ストアを使用したり、特定のデータ タイプに合わせて最適化した場合の状態に基づいてタイプを選択したりすることを検討してください。これには、リレーショナル データベースの代わりに、またはリレーショナル データベースと同時に、Table Storage、ドキュメント データベース、列ファミリ データ ストアを使用することが含まれます。詳細については、「[Data partitioning guidance (データのパーティション分割のガイダンス)](best-practices-data-partitioning.md)」を参照してください。
- **結果整合性を考慮して設計します**。結果整合性を取り入れると、複数のストアに分割された関連データを同期するために必要な時間が短縮されたり、またはその時間がなくなったりするため、スケーラビリティが向上します。ただしその反面、データはその読み取り時に常に整合性があるとは限りません。また、書き込み操作によっては競合が生じる場合があります。結果整合性は、同じデータの読み取りは頻繁に行われるが、書き込みはめったに行われない場合に有効です。詳細については、「[Data Consistency Primer (データ整合性入門)](https://msdn.microsoft.com/library/dn589800.aspx)」を参照してください。
- **コンポーネントとサービスの間の煩雑なやりとりを削減します**。対話型のやりとりを要する設計は避けてください。こうした設計を行うと、アプリケーションがすべてのデータを 1 回のサービス呼び出しで返すのではなく、サービスを複数回呼び出す必要が生じます (各回の呼び出しで、データは少量ずつしか返されません)。サービスまたはコンポーネントの呼び出しに著しい待ち時間が生じる場合、可能であれば関連するいくつかの操作を組み合わせて 1 つの要求にまとめてください。そうすることで、パフォーマンスの監視と複雑な操作の最適化を容易に実行できます。たとえば、データベースでストアド プロシージャを使用して、複雑なロジックをカプセル化し、ラウンド トリップおよびリソース ロックの回数を減らすことができます。
- **キューを使用して負荷を均等にすることで、高速なデータ書き込みを可能にします**。サービス要求の急増がそのサービスを圧迫し、障害を悪化させる可能性があります。これを防ぐには、[キュー ベースの負荷平準化パターン](https://msdn.microsoft.com/library/dn589783.aspx)の実装を検討してください。タスクとそのタスクが呼び出すサービスとの間でバッファとして機能するキューを使用します。これにより、サービスの障害やタスクのタイムアウトを引き起こしうる断続的で重大な負荷を平準化することができます。
- **データ ストアへの負荷を最小化します**。一般に、データ ストアは処理のボトルネックになる、コストの高いリソースです。また多くの場合、スケールアウトが容易ではありません。可能であれば、データ ストアからロジック (XML 文書や JSON オブジェクトの処理など) を除去し、アプリケーション内で処理を実行してください。たとえば、XML を (ストレージの不明瞭な文字列以外として) データベースに渡す代わりに、アプリケーション層内で XML をシリアル化/逆シリアル化し、ネイティブな形式でデータ ストアに渡します。通常、アプリケーションをスケールアウトする方がデータ ストアをスケールアウトするよりはるかに容易なので、多くのコンピューティング処理を要する処理はできるだけアプリケーション内で実行する必要があります。
- **取得するデータの量を最小化します**。列を指定し、条件を使用して行を選択することにより、必要なデータのみ取得します。テーブル値パラメーターおよび適切な分離レベルを使用します。エンティティ タグなどのメカニズムを使用して、不要なデータを取得しないようにします。
- **キャッシングを積極的に使用します**。可能な限りキャッシングを使用して、データを生成または配信するリソースおよびサービスへの負荷を削減してください。通常、キャッシュは、比較的静的なデータ、または取得のためにかなりの量の処理を必要とするデータに適しています。キャッシングは、データ アクセスとユーザー インターフェイスの生成などのアプリケーションの各層で、必要に応じてすべてのレベルで行う必要があります。詳細については、「[Caching Guidance (キャッシュのガイダンス)](best-practices-caching.md)」を参照してください。
- **データの増大および保存に対処します**。アプリケーションが格納するデータの量は、時間の経過と共に増大します。この増大により、ストレージ コストは上昇し、データ アクセス時の待ち時間も増加します。このことは、アプリケーションのスループットおよびパフォーマンスに影響を与えます。アクセスされなくなっている古いデータを定期的にアーカイブするか、めったにアクセスしないデータを、アクセスの待ち時間がより長いが、コスト効率の良い長期保存向けのストレージに移動したりできる可能性があります。
- **効率の良いバイナリ形式でデータ転送オブジェクト (DTO) を最適化します**。DTO はアプリケーションの層の間で何度も渡されます。サイズを最小化すると、リソースとネットワークへの負荷が軽減されます。ただし、データが使用される各場所で、データを必要な形式に変換するオーバーヘッドと負荷軽減とのバランスを保つようにします。コンポーネントの再利用を容易にするために、相互運用性の最も高い形式を採用してください。
- **キャッシュ制御を設定します**。可能な限り、出力キャッシングまたはフラグメント キャッシングを使用して、処理負荷を最小限に抑えるようにアプリケーションを設計および構成します。
- **クライアント側キャッシングを有効にします**。Web アプリケーションでは、キャッシュ可能なコンテンツ上でキャッシュ設定を有効にする必要があります。通常、規定では無効になっています。プロキシ サーバーおよびクラアント上でコンテンツのキャッシングを有効にするために、適切なキャッシュ制御ヘッダーを提供するようサーバーを構成します。
- **Azure BLOB Storage と Azure Content Delivery Network を使用して、アプリケーションへの負荷を軽減します**。イメージ、リソース、スクリプト、スタイル シートといった静的または比較的静的なパブリック コンテンツを Blob Storage に格納することを検討してください。このアプローチにより、要求ごとにこのコンテンツを動的に生成することで発生する負荷をアプリケーションから除くことができます。さらに、Content Delivery Network を使用してこのコンテンツをキャッシュし、クライアントに配信することを検討してください。Content Delivery Network を使用すると、クライアント側のパフォーマンスを向上できます。なぜなら、コンテンツは、Content Delivery Network キャッシュを利用できる地理的に最も近いデータセンターから配信されるからです。詳細については、「[Content Delivery Network (CDN) のガイダンス](best-practices-cdn.md)」を参照してください。
- **SQL クエリおよびインデックスを最適化し、調整します**。T-SQL ステートメントまたはコンストラクトの中には、パフォーマンスに影響を与えるものがあります。この影響は、ストアード プロシージャでコードを最適化することにより軽減できます。たとえば、**datetime** 型を **varchar** に変換してから **datetime** リテラル値と比較しないでください。代わりに日付/時刻比較関数を使用します。適切なインデックスがないと、クエリの実行が遅くなる可能性があります。オブジェクト/リレーショナル マッピング フレームワークを使用する場合、その動作およびデータ アクセス層のパフォーマンスへの影響を理解しておく必要があります。詳細については、「[クエリのチューニング](https://technet.microsoft.com/library/ms176005.aspx)」を参照してください。
- **データの非正規化を検討します**。データの非正規化により、重複や不整合を避けることができます。しかし、複数のインデックスを保守する、参照整合性を検査する、小さいデータ チャンクに複数回アクセスを実行する、テーブルを結合してデータを再アセンブルするといった作業が必要になるため、オーバーヘッドが生じて、パフォーマンスに影響を与える可能性があります。データ ストアへの負荷を軽減するために、追加のストレージ ボリュームおよび重複を受け入れられるかどうかを検討してください。また、データ ストアへの負荷を軽減するために、参照整合性の管理などのタスクの引き継ぎにアプリケーションそのもの (通常は、スケーリングがより容易) を利用できるかどうかも検討してください。詳細については、「[Data partitioning guidance (データのパーティション分割のガイダンス)](https://github.com/mspnp/azure-guidance/blob/master/Data%20partitioning.md)」を参照してください。

## サービスの実装
- **非同期呼び出しを使用します**。I/O またはネットワーク帯域幅によって制限される可能性があるリソースまたはサービス、あるいは著しい待ち時間があるリソースまたはサービスにアクセスする際には、呼び出し側のスレッドをロックしないために、可能な限り非同期コードを使用します。非同期動作を実装するには、[タスク ベースの非同期パターン (TAP)](https://msdn.microsoft.com/library/hh873175.aspx) を使用します。
- **リソースのロックを避け、代わりにオプティミスティック アプローチを使用します**。ストレージなどのリソースまたは著しい待ち時間がある他のサービスへのアクセスをロックしないでください。なぜなら、パフォーマンス低下の主な原因は、このロックだからです。ストレージへの書き込みなどの並行操作の管理には、常にオプティミスティック アプローチを使用してください。また、競合の管理には、ストレージ層の機能を使用してください。分散化アプリケーションでは、データの一貫性は最終的にしか保たれない場合があります。
- **高遅延で低帯域幅のネットワークを使用する場合、高圧縮可能なデータを圧縮します**。Web アプリケーションではほとんどの場合、アプリケーションによって生成され、ネットワーク上で渡される最大のデータは、クライアントの要求に対する HTTP 応答です。この大きさは、HTTP 圧縮により、大幅に縮小できます。特に静的コンテンツの場合には効果的です。これにより、コストを削減できるだけでなく、ネットワークへの負荷も削減できます。ただし、動的コンテンツの圧縮では、部分的に高い負荷がサーバーにかかります。より汎用的な他の環境では、データを圧縮してデータ転送量を削減することで、転送時間とコストを最小化できますが、圧縮と展開のプロセスによるオーバーヘッドが発生します。そのため、データ圧縮は、パフォーマンス面で明らかなメリットがある場合に限り使用する必要があります。JSON やバイナリ エンコーディングなど、他のシリアル化方式では、パフォーマンスにそれほど影響を与えずに、ペイロード サイズを減らすことができます。一方、XML ではペイロード サイズが増加する可能性があります。
- **接続およびリソースが使用されている時間を最小限にします。**。接続およびリソースは、必要な期間だけ維持します。たとえば、接続を開くのはできるだけ遅く、接続プールに返すのはできるだけ早くします。リソースの取得はできるだけ遅くし、解放はできるだけ早くします。
- **必要な接続の数を最小限にします**。サービス接続はリソースを消費します。必要な数を制限し、可能な場合には既存の接続を再利用するようにします。たとえば、認証の実行後、必要に応じて権限借用を使用し、コードを特定の ID として実行します。これにより、接続が再利用されるため、接続プールを最大限に活用できます。

	> [AZURE.NOTE]一部のサービスの API では、サービス固有のガイドラインが守られていることを前提に接続が自動的に再利用されます。アプリケーションで使用される各サービスに対して接続の再利用を有効にする条件を理解しておくことが重要です。

- **要求をバッチで送信して、ネットワークの使用を最適化します**。たとえば、キューにアクセスするときにはメッセージの送信および読み取りをバッチで行い、ストレージまたはキャッシュにアクセスするときには複数の読み取りまたは書き込みをバッチとして実行します。このように、ネットワーク上の呼び出しの数を減らすことで、サービスおよびデータ ストアの効率を最大限に高めることができます。
- 可能な場合には、**サーバー側のセッション状態を格納しないで済むようにします**。通常、サーバー側のセッション状態の管理にはクライアント アフィニティが必要です (つまり、各要求を同じサーバー インスタンスにルーティングします)。これはシステムのスケール能力に影響を与えます。理想的には、クライアントが使用するサーバーに対して、クライアントをステートレスに設計する必要があります。ただし、アプリケーションがセッション状態を維持する必要がある場合、機密性の高いデータまたはクライアントごとの大量データは、アプリケーションのすべてのインスタンスがアクセスできる分散されたサーバー側のキャッシュに格納してください。
- **テーブル ストレージ スキーマを最適化します**。Azure Table Storage のように、テーブルと列の名前をクエリごとに渡して処理する必要があるテーブル ストアを使用する場合は、このオーバーヘッドを減らすために短い名前の使用を検討してください。ただし、名前を極端に短くして、読みやすさや管理の容易さが犠牲にならないようにします。
- **タスク並列ライブラリ (TPL) を利用して、非同期操作を実行します。**TPL により、I/O バウンド型の操作を実行する非同期コードの書き込みが容易になります。可能な限り、_ConfigureAwait(false)_ を使用して、特定の同期コンテキストに対する継続の依存関係をなくします。こうすることで、スレッドのデッドロックが発生する可能性が低下なります。
- **デプロイメント中またはアプリケーションのスタートアップ時にリソースの依存関係を作成します**。リソースが存在するかどうかをテストするメソッドを繰り返し呼び出して、リソースが存在しない場合に作成するというロジックは組み込まないでください (Azure Storage クライアント ライブラリ内の _CloudTable.CreateIfNotExists_ や _CloudQueue.CreateIfNotExists_ などのメソッドは、このパターンに該当します)。ストレージ テーブルまたはストレージ キューにアクセスする前に、毎回これらのメソッドが呼び出される場合、著しいオーバーヘッドが生じる可能性があります。その代わりに、次の方法を使用します。
 - アプリケーションのデプロイ時または初回の起動時に必要なリソースを作成します (各リソースについて、Web ロールまたは worker ロール用のスタートアップ コードで _CreateIfNotExists_ を 1 回呼び出すのが適切です)。ただし、存在しないリソースに対してコードがアクセスしようとする場合に生じる可能性がある例外を必ず処理します。こうした状況では、例外を記録し、リソースが見つからないことをオペレーターに可能な限り警告する必要があります。
 - 状況によっては、見つからないリソースを例外処理コードの一部として作成することが適切です。ただし、リソースが見つからない理由として、プログラミング エラー (リソース名のスペルミスなど) や他のインフラストラクチャ レベルの問題も考えられるため、このアプローチは慎重に採用する必要があります。
- **軽量フレームワークを使用します**。リソース使用量、実行時間、アプリケーションへの全体的な負荷を最小限にするために、使用する API およびフレームワークを慎重に検討します。たとえば、Web API を使用してサービス要求を処理すると、アプリケーションのフットプリントが小さくなり、実行速度が向上します。しかし、Windows Communication Foundation の追加機能が必要となる高度なシナリオには適さない場合があります。
- **サービス アカウントの数を最小限にすることを検討します**。たとえば、接続に制限が課されているリソースまたはサービスにアクセスしたり、維持する接続の数を少なくするとパフォーマンスが向上したりする場合は、固有のアカウントを使用します。このアプローチは、データベースなどのサービスには一般的ですが、元のユーザーの権限借用であるため、操作を正確に監査する能力に影響する可能性があります。
- 開発中のテスト ルーチンの一環として、および最終リリースの前に、**パフォーマンスのプロファイリングおよび負荷テストを行って**、アプリケーションのパフォーマンスおよびスケーリングが要求どおりであることを確認します。このテストは、運用プラットフォームと同じタイプのハードウェアに対して、さらに運用中に生じるデータおよびユーザー負荷と同じタイプおよび数量を用いて実行する必要があります。詳細については、「[クラウド サービスのパフォーマンスのテスト](vs-azure-tools-performance-profiling-cloud-services.md)」を参照してください。

<!---HONumber=AcomDC_0330_2016-->