<properties
   pageTitle="スケーラビリティのチェックリスト|Microsoft Azure"
   description="Azure 自動スケールの設計に関するスケーラビリティのチェックリスト ガイダンス。"
   services=""
   documentationCenter="na"
   authors="dragon119"
   manager="masimms"
   editor=""
   tags=""/>

<tags
   ms.service="best-practice"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="na"
   ms.date="12/16/2015"
   ms.author="masashin"/>

# スケーラビリティのチェックリスト

![](media/best-practices-scalability-checklist/pnp-logo.png)

## サービスの設計
- **ワークロードを分割します**。プロセスのパーツを別個に分解できるように設計します。また、処理内容の独立の一般規則および単一責任の法則に従って、各パーツのサイズは最小限にします。これにより、各コンピューティング ユニット (ロールまたはデータベース サーバーなど) を最大限に使用できるようにコンポーネントのパーツを分散できます。また、特定のリソースのインスタンスを追加することで、アプリケーションのスケーリングが容易になります。詳細については、「[Compute Partitioning Guidance (コンピューティング パーティション分割のガイダンス)](https://msdn.microsoft.com/library/dn568099.aspx)」を参照してください。
- **スケーリングを考慮して設計します**。スケーリングにより、アプリケーションは、ロール、キュー、および使用する他のサービスのインスタンスの数を増減することで、変動負荷に対応できます。ただし、アプリケーションを設計する際には、次の点を考慮に入れる必要があります。たとえば、アプリケーションとそれが使用するサービスはステートレスにして、要求をどのインスタンスにもルーティングできるようにする必要があります。また、特定のインスタンスの追加または削除によって、現行ユーザーに悪影響が及ぶことがないようにします。さらに、インスタンスの追加/削除を自動検出して、インスタンスの再構成を行うしくみを実装して、アプリケーション内のコードが必要なルーティングを実行できるようにする必要があります。たとえば、Web アプリケーションは一連のキューをラウンド ロビン方式で使用して、worker ロールで実行しているバックグラウンド サービスに要求をルーティングする場合があります。Web アプリケーションは、要求を正しくルーティングして、アプリケーションへの負荷を均等にするために、キューの数の変更を検出できる必要があります。
- **ユニットとしてスケールします**。成長に合わせてリソースを追加するように計画します。リソースごとに、スケーリングの上限を確認し、シャーディングまたは分解を使用して、これらの限度を超える必要があります。明確に定義されたリソースのセットを単位として、システムのスケール ユニットを判別します。これにより、スケールアウト操作の適用が容易になるだけでなく、システム全体のある部分でリソースが不足しているために制限が課され、アプリケーションに悪影響を及ぼす可能性を避けることができます。たとえば、x 個の Web ロールおよび worker ロールを追加すると、それらのロールによって生成される追加のワークロードを処理するために、y 個の追加キューおよび z 個のストレージ アカウントが必要な場合、スケール ユニットは x 個の Web ロールおよび worker ロール、_y_ 個のキュー、_z_ 個のストレージ アカウントで構成されます。1 つ以上のスケール ユニットを追加することでスケーリングが容易になるように、アプリケーションを設計してください。
- **クライアント アフィニティを回避します**。可能であれば、どのインスタンスにも要求をルーティングできるように、またインスタンスの数に影響されずに済むように、アプリケーションでアフィニティを要求しないようにします。これにより、各ユーザーの状態情報を格納、取得、保守するためのオーバーヘッドが生じることもなくなります。
- **プラットフォーム自動スケール機能を活用します**。ホスティング プラットフォームが Azure Autoscaling などの自動スケール機能をサポートする場合、組み込みのメカニズムで要求を満たせない場合を除き、カスタムまたはサードパーティのメカニズムではなく自動スケール機能を使用してください。可能な限り、スケジュールされたスケーリング ルールを使用し、起動時の遅延なしでリソースを使用可能にします。しかし、必要に応じてリアクティブ自動スケールをルールに追加し、予期しない要求の変化に対応する必要があります。サービス管理 API で自動スケール操作を使用して、自動スケールを微調整したり、Web ポータルで使用可能な構成オプション以外にカスタム カウンターをルールに追加したりできます。詳細については、「[Auto-scaling guidance (自動スケールのガイダンス)](best-practices-auto-scaling.md)」ページを参照してください。
- **負荷の高い CPU/IO タスクをバックグラウンド タスクとしてオフロードします**。サービスへの要求の実行に長時間かかったり、かなりのリソースを消費したりすることが予測される場合、この要求の処理を別個のタスクにオフロードします。(ホスティング プラットフォームに応じ、) worker ロールまたはバックグラウンド ジョブを使用して、これらのタスクを実行します。この戦略を使用すると、サービスはさらに多くの要求を引き続き受信したり、即座に対応したりすることが可能になります。詳細については、「[Background jobs guidance (バックグラウンド ジョブのガイダンス)](best-practices-background-jobs.md)」を参照してください。
- **バックグラウンド タスクのワークロードを分散します**。多くのバックグラウンド タスクがある場合、またはタスクの実行に相当の時間かリソースが必要な場合、複数のコンピューティング ユニット (worker ロールまたはバックグラウンド ジョブなど) に作業を分散します。考えられる解決策の 1 つは、[競合コンシューマー パターン](https://msdn.microsoft.com/library/dn568101.aspx)を利用することです。
- **_シェアード ナッシング_ アーキテクチャの使用を考慮します**。シェアード ナッシング アーキテクチャでは、ノードは独立しており、自律的であり、共有システムやストレージなどの単一競合箇所がありません。理論上、そのようなシステムはほぼ無制限にスケールできます。一般に、完全なシェアード ナッシング アプローチはほとんどのアプリケーションで実用的ではありませんが、スケーラビリティの向上を考慮に入れた設計には適している場合があります。たとえば、サーバー側のセッション状態、クライアント アフィニティ、データのパーティション分割の使用を避けることは、シェアード ナッシング アーキテクチャを使用する良い例です。

## データ管理

- **データのパーティション分割を使用します**。データを複数のデータベースおよびデータベース サーバーに分割するか、またはこのパーティション分割を透過的に実行できるデータ ストレージ サービスを使用するようにアプリケーションを設計します (サービスの一例として、Azure SQL Database Elastic Scale や Azure テーブル ストレージがあります)。このアプローチを使用すると、パフォーマンスを最大化すると同時に、スケーリングを容易にすることが可能です。パーティション分割には、水平的パーティション分割、垂直的パーティション分割、および機能的パーティション分割など、さまざまな技法があります。これらを組み合わせて使用すると、クエリのパフォーマンスの向上、シンプル化されたスケーラビリティ、より柔軟性のある管理、可用性の向上から得られるメリットを最大限に活用できるだけでなく、保持されるデータとデータ ストアの種類を一致させることができます。さらに、データ タイプに応じて異なる種類のデータ ストアを使用したり、特定のデータ タイプに合わせて最適化した場合の状態に基づいてタイプを選択したりすることを検討してください。これには、リレーショナル データベースの代わりに、またはリレーショナル データベースと同時に、テーブル ストレージ、ドキュメント データベース、列ファミリ データ ストアを使用することが含まれます。詳細については、「[Data partitioning guidance (データのパーティション分割のガイダンス)](best-practices-data-partitioning.md)」を参照してください。
- **結果整合性を考慮して設計します**。結果整合性を取り入れると、複数のストアに分割された関連データを同期するために必要な時間が短縮されたり、またはその時間がなくなったりするため、スケーラビリティが向上します。ただしその反面、データはその読み取り時に常に整合性があるとは限りません。また、書き込み操作によっては競合が生じる場合があります。結果整合性は、同じデータの読み取りは頻繁に行われるが、書き込みはめったに行われない場合に有効です。詳細については、「[Data consistency guidance (データ整合性のガイダンス)](#insertlink#)」を参照してください。
- **コンポーネントとサービスの間の煩雑なやりとりを削減します**。サービス用に_煩雑な_インターフェイスを設計しないでください。煩雑なインターフェイスを設計すると、アプリケーションは、すべてのデータを返すことが可能な 1 回のサービス呼び出しではなく、サービスを複数回呼び出すことが必要になります (それぞれの呼び出しでは少量のデータしか返されません)。サービスまたはコンポーネントの呼び出しに著しい待ち時間が生じる場合、可能であれば関連するいくつかの操作を組み合わせて 1 つの要求にまとめてください。そうすることで、パフォーマンスの監視と複雑な操作の最適化を容易に実行できます。たとえば、データベースでストアード プロシージャを使用して複雑なロジックをカプセル化し、ラウンド トリップとびリソース ロックの回数を減らすことができます。 
- **キューを使用して負荷を均等にすることで、高速なデータ書き込みを可能にします**。サービス要求の急増がそのサービスを圧迫し、障害を悪化させる可能性があります。これを防ぐには、[キュー ベースの負荷平準化パターン](https://msdn.microsoft.com/library/dn589783.aspx)の実装を検討してください。タスクとそのタスクが呼び出すサービスの間のバッファーの役目をするキューを使用して、サービスの障害やタスクのタイム アウトにつながる可能性がある断続的な大きい負荷を平準化することができます。
- **データ ストアへの負荷を最小化します**。一般に、データ ストアは処理のボトルネックになる、コストの高いリソースです。また多くの場合、スケールアウトが容易ではありません。可能であれば、データ ストアからロジック (XML 文書や JSON オブジェクトの処理など) を除去し、アプリケーション内で処理を実行してください。たとえば、XML を (ストレージの不明瞭な文字列以外として) データベースに渡す代わりに、アプリケーション層内で XML をシリアル化/逆シリアル化し、データ ストアにとってネイティブな形式で渡します。通常、アプリケーションをスケールアウトするほうがデータ ストアをスケールアウトするよりはるかに容易です。したがって、多くのコンピューティング処理を要する処理はできるだけアプリケーション内で行うようにする必要があります。
- **取得するデータの量を最小化します**。列を指定し、条件を使用して行を選択することにより、必要なデータのみ取得します。テーブル値パラメーターおよび適切な分離レベルを使用します。ETags などのメカニズムを使用してデータを不必要に取得しないようにします。
- **キャッシングを積極的に使用します**。可能な限りキャッシングを使用して、データを生成または配信するリソースおよびサービスへの負荷を削減してください。通常、キャッシュは、比較的静的なデータ、または取得のためにかなりの量の処理を必要とするデータに適しています。キャッシングは、データ アクセスおよび UI の生成などのアプリケーションの各層で、必要に応じてすべてのレベルで行う必要があります。詳細については、「[Caching Guidance (キャッシュのガイダンス)](best-practices-caching.md)」を参照してください。
- **データの増大および保存に対処します**。アプリケーションが格納するデータの量は、時間の経過とともに増大します。この増大により、ストレージ コストは上昇し、データ アクセス時の待ち時間も増加します。このことはアプリケーションのスループットおよびパフォーマンスに影響を与えます。アクセスされなくなっている古いデータを定期的にアーカイブするか、めったにアクセスしないデータを、アクセスの待ち時間がより長いが、コスト効率の良い長期保存向けのストレージに移動したりできる可能性があります。
- **効率の良いバイナリ形式で DTO を最適化します**。データ転送オブジェクトはアプリケーションの層の間で何度も渡されるため、サイズを最小化すれば、リソースおよびネットワークへの負荷が軽減されます。ただし、データが使用される各ロケーションでデータを必要な形式に変換するオーバーヘッドと負荷軽減とのバランスを保ち、コンポーネントの再利用を容易にするために相互運用性の最も高い形式を採用してください。
- **キャッシュ制御を設定します**。可能な限り出力キャッシングまたはフラグメント キャッシングを使用して、処理負荷を最小限に抑えるようにアプリケーションを設計および構成します。
- **クライアント側キャッシングを有効にします**。Web アプリケーションでは、キャッシュ可能なコンテンツ上でキャッシュ設定を有効にする必要があります。通常、規定では無効になっています。プロキシ サーバーおよびクラアント上でコンテンツのキャッシングを有効にするために、適切なキャッシュ制御ヘッダーを提供するようサーバーを構成します。
- **Azure BLOB ストレージおよび CDN を使用して、アプリケーションへの負荷を軽減します**。イメージ、リソース、スクリプト、スタイル シートといった静的または比較的静的なパブリック コンテンツを BLOB ストレージに格納することを検討してください。このアプローチにより、要求ごとにこのコンテンツを動的に生成することで発生する負荷をアプリケーションから除くことができます。さらに、CDN を使用してこのコンテンツをキャッシュし、クライアントに配信することを検討してください。CDN を使用すると、クライアント側のパフォーマンスを向上できます。なぜなら、コンテンツは地理的に最も近くにある、CDN キャッシュを利用できるデータセンターから配信されるからです。詳細については、「[コンテンツ配信ネットワーク (CDN) のガイダンス](best-practices-cdn.md)」を参照してください。

- **SQL クエリおよびインデックスを最適化し、調整します**。T-SQL ステートメントまたはコンストラクトの中には、パフォーマンスに影響を与えるものがあります。この影響は、ストアード プロシージャでコードを最適化することにより軽減できます。たとえば、**datetime** 型を **varchar** に変換してから **datetime** リテラル値と比較するのは避ける必要があります。その代わりに、日付/時刻比較関数を使用します。適切なインデックスがないと、クエリの実行が遅くなる可能性があります。オブジェクト/リレーショナル マッピング (ORM) フレームワークを使用する場合、その動作およびデータ アクセス層のパフォーマンスへの影響を理解しておく必要があります。詳細については、「[クエリのチューニング](https://technet.microsoft.com/library/ms176005.aspx)」を参照してください。
- **データの非正規化を検討します**。データの非正規化により、重複や不整合を避けることができます。しかし、複数のインデックスを保守する、参照整合性を検査する、小さいデータ チャンクに複数回アクセスを実行する、テーブルを結合してデータを再アセンブルするといった作業が必要になるため、オーバーヘッドが生じて、パフォーマンスに影響を与える可能性があります。データ ストアへの負荷を軽減するために、追加のストレージ ボリュームおよび重複を受け入れられるかどうかを検討してください。また、データ ストアへの負荷を軽減するために、参照整合性の管理などのタスクの引き継ぎにアプリケーションそのものを利用できるかどうか (通常は、スケーリングがより容易です) も検討してください。詳細については、「[Data partitioning guidance (データのパーティション分割のガイダンス)](https://github.com/mspnp/azure-guidance/blob/master/Data%20partitioning.md)」を参照してください。

## サービスの実装
- **非同期呼び出しを使用します**。I/O またはネットワーク帯域幅によって制限される可能性があるリソースまたはサービス、あるいは著しい待ち時間があるリソースまたはサービスにアクセスする際には、呼び出し側のスレッドをロックしないために、可能な限り非同期コードを使用します。非同期動作を実行するには、タスク ベースの非同期パターンを実装します。詳細については、Microsoft の Web サイトの「[タスク ベースの非同期パターン (TAP)](https://msdn.microsoft.com/library/hh873175.aspx)」ページを参照してください。
- **リソースのロックを避け、代わりにオプティミスティック アプローチを使用します**。ストレージなどのリソースまたは著しい待ち時間がある他のサービスへのアクセスをロックしないでください。なぜなら、パフォーマンス低下の主な原因は、このロックだからです。ストレージへの書き込みなどの並行操作の管理には、常にオプティミスティック アプローチを使用してください。また、競合の管理には、ストレージ層の機能を使用してください。分散化アプリケーションでは、データの一貫性は最終的にしか保たれない場合があります。
- **高遅延で低帯域幅のネットワークを使用する場合、高圧縮可能なデータを圧縮します**。Web アプリケーションではほとんどの場合、アプリケーションによって生成され、ネットワーク上で渡される最大のデータは、クライアントの要求に対する HTTP 応答です。この大きさは、HTTP 圧縮により、大幅に縮小できます。特に静的コンテンツの場合には効果的です。これにより、コストを削減できるだけでなく、ネットワークへの負荷も削減できます。ただし、動的コンテンツの圧縮は、部分的に高い負荷がサーバーに適用されます。より汎用的な他の環境では、データ圧縮を圧縮して転送されるデータの量を削減することで、転送時間およびコストを最小化できます。ただし、圧縮プロセスおよび展開プロセスによるオーバーヘッドが発生します。そのため、データ圧縮は、パフォーマンス面で明らかなメリットがある場合に限り使用する必要があります。JSON やバイナリ エンコーディングなど、他のシリアル化方式では、パフォーマンスにそれほど影響を与えずに、ペイロード サイズを減らすことができます。一方、XML ではパフォーマンスへの負荷が増加する可能性があります。
- **接続およびリソースが使用されている時間を最小限にします。**。接続およびリソースは、必要な期間だけ維持します。たとえば、接続を開くのはできるだけ遅く、接続プールに返すのはできるだけ早くします。リソースの取得はできるだけ遅くし、できるだけ早く解放します。
- **必要な接続の数を最小限にします**。サービス接続はリソースを消費します。可能な限り必要な数を制限し、可能な場合には既存の接続を再利用するようにします。たとえば、認証の実行後、必要に応じて権限借用を使用し、コードを特定の ID として実行します。これにより、接続が再利用されるため、接続プールを最大限に活用できます。 

	> [AZURE.NOTE]\:** 一部のサービスの API では、サービス固有のガイドラインが守られていることを前提に接続が自動的に再利用されます。アプリケーションで使用される各サービスに対して接続の再利用を有効にする条件を理解しておくことが重要です。
- **要求をバッチで送信して、ネットワークの使用を最適化します**。たとえば、キューにアクセスするときにはメッセージの送信および読み取りをバッチで行い、ストレージまたはキャッシュにアクセスするときには複数の読み取りまたは書き込みをバッチとして実行します。このように、ネットワーク上の呼び出しの数を減らすことで、サービスおよびデータ ストアの効率を最大限に高めることができます。
- 可能な場合には、**サーバー側のセッション状態を格納しないで済むようにします**。通常、サーバー側のセッション状態の管理にはクライアント アフィニティが必要です (つまり、各要求を同じサーバー インスタンスにルーティングします)。これはシステムのスケール能力に影響を与えます。理想的には、クライアントが使用するサーバーに対して、クライアントをステートレスに設計する必要があります。ただし、アプリケーションがセッション状態を維持する必要がある場合、機密性の高いデータまたはクライアントごとの大量データは、アプリケーションのすべてのインスタンスがアクセスできる分散されたサーバー側のキャッシュに格納してください。
- **テーブル ストレージ スキーマを最適化します**。Azure テーブル ストレージなどのように、テーブルおよび列の名前をクエリごとに渡して処理する必要があるテーブル ストアを使用する場合、このオーバーヘッドを減らすために短い名前の使用を検討してください。ただし、読みやすさや管理の容易さを犠牲にせず、そのうえで直観的でない短い名前を使用してください。
- **TPL を利用して、非同期操作を実行します**。タスク並列ライブラリ (TPL) により、I/O バウンド型の操作を実行する非同期コードの書き込みが容易になります。可能な限り、_ConfigureAwait(false)_ を使用して、特定の同期コンテキストに対する継続の依存関係をなくし、スレッドのデッドロックが発生しないようにしてください。
- **デプロイメント中またはアプリケーションのスタートアップ時にリソースの依存関係を作成します**。リソースが存在するかどうかをテストするメソッドを繰り返し呼び出して、リソースが存在しない場合には作成するというロジックは組み込まないでください (Azure Storage クライアント ライブラリ内の _CloudTable.CreateIfNotExists_ や _CloudQueue.CreateIfNotExists_ などのメソッドはこのパターンに該当します)。ストレージ テーブルまたはストレージ キューにアクセスする前に、毎回これらのメソッドが呼び出される場合、著しいオーバーヘッドが生じる可能性があります。その代わりに、アプリケーションのデプロイ時または初回の始動時に必要なリソースを作成します (各リソースについて、Web ロールまたは worker ロール用のスタートアップ コードで _CreateIfNotExists_ を 1 回呼び出すのが適切です)。ただし、存在しないリソースに対してコードがアクセスしようとする場合に生じる可能性がある例外を必ず処理します。こうした状況では、例外を記録し、リソースが見つからないことをオペレーターに可能な限り警告する必要があります。ある状況では、見つからないリソースを例外処理コードの一部として作成することが適切です。しかし、リソースが見つからない理由として、プログラミング エラー (リソース名のスペルミスなど) や他のインフラストラクチャ レベルの問題が考えられるため、このアプローチは慎重に採用する必要があります。
- **軽量フレームワークを使用します**。リソース使用量、実行時間、アプリケーションへの全体的な負荷を最小限にするために、使用する API およびフレームワークを慎重に検討します。たとえば、Web API を使用してサービス要求を処理すると、アプリケーションのフットプリントが小さくなり、実行速度が向上します。しかし、WCF の追加機能が必要となるような高度のシナリオには適していない場合があります。
- **サービス アカウントの数を最小限にすることを検討します**。たとえば、接続に制限が課されているリソースまたはサービスにアクセスしたり、維持する接続の数を少なくするとパフォーマンスが向上したりする場合は、固有のアカウントを使用します。このアプローチは、データベースなどのサービスには一般的ですが、元のユーザーの権限借用であるため、操作を正確に監査する能力に影響する可能性があります。
- 開発中のテスト ルーチンの一環として、および最終リリースの前に、**パフォーマンスのプロファイリングおよび負荷テストを行って**、アプリケーションのパフォーマンスおよびスケーリングが要求どおりであることを確認します。このテストは、運用プラットフォームと同じタイプのハードウェアに対して、さらに運用中に生じるデータおよびユーザー負荷と同じタイプおよび数量を用いて実行する必要があります。詳細については、Microsoft の Web サイトの「[クラウド サービスのパフォーマンスのテスト](https://azure.microsoft.com/documentation/articles/vs-azure-tools-performance-profiling-cloud-services)」ページを参照してください。

<!---HONumber=AcomDC_0316_2016-->