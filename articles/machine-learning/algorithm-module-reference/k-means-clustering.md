---
title: 'K-Means Clustering (K-Means クラスタリング): モジュール リファレンス'
titleSuffix: Azure Machine Learning
description: Azure Machine Learning の K-Means クラスタリング モジュールを使用して、クラスタリング モデルをトレーニングする方法について説明します。
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference
author: likebupt
ms.author: keli19
ms.date: 11/19/2019
ms.openlocfilehash: 6e2fa96584570e5837c4367c8be4701b7398fb0f
ms.sourcegitcommit: 812bc3c318f513cefc5b767de8754a6da888befc
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 02/12/2020
ms.locfileid: "77152212"
---
# <a name="module-k-means-clustering"></a>モジュール:K-Means クラスタリング

この記事では、Azure Machine Learning デザイナー (プレビュー) で *K-Means クラスタリング* モジュールを使用して、トレーニングされていない K-Means クラスタリング モデルを作成する方法について説明します。 
 
K-Means は、最も単純であり、よく知られている "*教師なし*" 学習アルゴリズムの 1 つです。 以下のようなさまざまな機械学習タスクにこのアルゴリズムを使用できます。 

* [異常データの検出](https://msdn.microsoft.com/magazine/jj891054.aspx)。
* テキスト ドキュメントのクラスタリング。
* 他の分類法または回帰法を使用する前のデータセットの分析。 

クラスタリング モデルを作成するには、次の手順を実行します。

* このモジュールをパイプラインに追加します。
* データセットを接続します。
* 予想するクラスターの数、クラスターの作成に使用する距離メトリックなどのパラメーターを設定します。 
  
モジュールのハイパーパラメーターを構成したら、未トレーニングのモデルを [[Train Clustering Model]\(クラスタリング モデルのトレーニング\)](train-clustering-model.md) に接続します。 K-Means アルゴリズムは教師なし学習方法なので、ラベル列は省略可能です。 

+ データにラベルが含まれる場合は、ラベルの値を使用して、クラスターの選択を示し、モデルを最適化することができます。 

+ データにラベルがない場合、アルゴリズムによって、データのみに基づいて可能なカテゴリを表すクラスターが作成されます。  

##  <a name="understand-k-means-clustering"></a>K-Means クラスタリングの概要
 
一般に、クラスタリングは反復的な手法を使用して、データセット内のケースを同様の特性を持つクラスターにグループ化します。 これらのグループ化は、データを探索して、データ内の異常を識別し、最終的に予測を行うために便利です。 クラスタリング モデルは、参照またはシンプルな監視によって論理的に派生する可能性がないデータセットで、リレーションシップを識別するのにも役立ちます。 これらの理由から、クラスタリングは、データの詳細を確認し、予期しない相関を検出するために、機械学習タスクの初期フェーズで使用されることが多いです。  
  
 K-Means 法を使用してクラスタリング モデルを構成するときは、モデルに必要な "*重心*" の数を示すターゲット数 *k* を指定する必要があります。 重心は、各クラスターを代表する点です。 K-Means アルゴリズムでは、クラスター内の平方和を最小限にすることで、クラスターのいずれかに各受信データ ポイントを割り当てます。 
 
トレーニング データを処理すると、K-Means アルゴリズムではランダムに選択された重心の初期セットから開始されます。 重心はクラスターの出発点として機能し、Lloyd のアルゴリズムを適用して、その位置を反復的に絞り込みます。 次の条件の 1 つまたは複数に合致するときに、K-Means アルゴリズムによってクラスターのビルドと絞り込みが停止されます。  
  
-   重心は安定します。つまり、個々の点に対するクラスターの割り当ては変化しなくなり、アルゴリズムは解に収束しました。  
  
-   アルゴリズムによって、指定されたイテレーションの数の実行が完了している。  
  
 トレーニング フェーズが完了したら、[Assign Data to Clusters (クラスターへのデータの割り当て)](assign-data-to-clusters.md) モジュールを使用して、K-Means アルゴリズムを使用して検出されたクラスターの 1 つに新しいケースを割り当てます。 新しいケースと各クラスターの重心との間の距離を計算することで、クラスターの割り当てを実行します。 新しいケースはそれぞれ、最も近い重心を持つクラスターに割り当てられます。  

## <a name="configure-the-k-means-clustering-module"></a>K-Means クラスタリング モジュールを構成する
  
1.  **K-Means Clustering (K-Means クラスタリング)** モジュールを自分のパイプラインに追加します。  
  
2.  モデルのトレーニング方法を指定するには、 **[Create trainer mode]\(トレーナー モードの作成\)** オプションを選択します。  
  
    -   **Single Parameter (単一パラメーター)** : クラスタリング モデルで使用する正確なパラメーターを把握している場合は、特定の値のセットを引数として指定できます。  
  
3.  **[Number of centroids]\(重心の数\)** には、アルゴリズムを開始するクラスターの数を入力します。  
  
     このモデルは、この数のクラスターを正確に生成することが保証されていません。 このアルゴリズムは、この数のデータ ポイントから開始し、反復処理で最適な構成を見つけます。  
  
4.  プロパティ **[Initialization]\(初期化\)** は、初期クラスター構成の定義に使用されるアルゴリズムを指定するために使用されます。  
  
    -   **最初の N**: いくつかの初期データ ポイント数がデータセットから選択され、初期の手段として使用されます。 
    
         この方法は "*Forgy 法*" とも呼ばれます。  
  
    -   **ランダム**: アルゴリズムによって、クラスターにデータ ポイントがランダムに配置され、クラスターのランダムに割り当てられたポイントの重心になる初期平均値が計算されます。 

         この方法は "*ランダム パーティション*" 法とも呼ばれます。  
  
    -   **K-Means++** : これは、クラスターの初期化に対する既定のメソッドです。  
  
         標準の K-Means アルゴリズムによる低品質なクラスタリングを回避するために、2007 年、**K-Means ++** アルゴリズムが David Arthur と Sergei Vassilvitskii によって提案されました。 **K-Means ++** は、初期クラスターの中心を選択するために異なる方法を使用することで標準の K-Means を改良しています。  
  
    
5.  **[Random number seed]\(乱数シード\)** には、クラスターの初期化にシードとして使用する値を必要に応じて入力します。 この値は、クラスターの選択に大きな影響を及ぼすことがあります。  
  
6.  **[Metric]\(メトリック\)** で、クラスター ベクター間、または新しいデータ ポイントとランダムに選択された重心の間の距離を測定するために使用する関数を選びます。 Azure Machine Learning は、次のクラスターの距離のメトリックをサポートしています。  
  
    -   **ユークリッド**: ユークリッド距離は、一般的に K-Means クラスタリング用のクラスター散布図のメジャーとして使用されます。 ポイントと重心の間の平均距離が最小になるため、このメトリックが推奨されます。
  
7.  **[Iterations]\(イテレーション\)** に、重心の選択が完了するまでにアルゴリズムがトレーニング データを反復処理する回数を入力します。  
  
     このパラメーターを調整して、正確さとトレーニング時間のバランスをとることができます。  
  
8.  **[Assign label mode]\(ラベル モードの割り当て\)** では、ラベル列がデータセット内に存在する場合の処理方法を指定するオプションを選択します。  
  
     K-Means クラスタリングは教師なしの機械学習メソッドのため、ラベルは省略可能です。 ただし、データセットに既にラベル列がある場合は、それらの値を使用してクラスターの選択をガイドすることや、値を無視するように指定することができます。  
  
    -   **Ignore label column (ラベル列を無視する)** : ラベル列の値は無視され、モデルのビルドには使用されません。
  
    -   **Fill missing values (欠落値を入力する)** : ラベル列の値は、クラスターのビルドに役立つフィーチャーとして使用されます。 任意の行にラベルが不足している場合は、その値はその他のフィーチャーを使用することで補完されます。  
  
    -   **Overwrite from closest to center (中心に最も近い値から上書きする)** : ラベル列の値は、現在の重心に最も近いポイントのラベルを使用して、予測ラベル値に置き換えられます。  

8.  トレーニングの前に特徴を正規化する場合は、 **[Normalize features]\(特徴の正規化\)** オプションを選択します。
  
     正規化を適用すると、トレーニングの前に、MinMaxNormalizer によってデータ ポイントが `[0,1]` に正規化されます。

10. モデルをトレーニングする。  
  
    -   **[Create trainer mode]\(トレーナー モードの作成\)** を **[Single Parameter]\(単一パラメーター\)** に設定した場合、[Train Clustering Model (クラスタリング モデルのトレーニング)](train-clustering-model.md) モジュールを使用することで、タグ付けしたデータセットを追加してモデルをトレーニングします。  
  
### <a name="results"></a>[結果]

モデルの構成とトレーニングが完了したら、スコアの生成に使用できるモデルは完成です。 しかし、モデルのトレーニングには複数の方法があり、結果を表示して使用するには複数の方法があります。 

#### <a name="capture-a-snapshot-of-the-model-in-your-workspace"></a>ワークスペースでモデルのスナップショットをキャプチャする

[Train Clustering Model (クラスタリング モデルのトレーニング)](train-clustering-model.md) モジュールを使用した場合:

1. **[Train Clustering Model]\(クラスタリング モデルのトレーニング\)** モジュールを選択し、右側のパネルを開きます。

2. **[出力]** タブを選択します。 **[データセットの登録]** アイコンを選択して、トレーニング済みモデルのコピーを保存します。

保存されるモデルは、モデルを保存した時点のトレーニング データを表します。 パイプラインで使用したトレーニング データを後で更新しても、保存済みのモデルは更新されません。 

#### <a name="see-the-clustering-result-dataset"></a>クラスタリングの結果のデータセットを表示する 

[Train Clustering Model (クラスタリング モデルのトレーニング)](train-clustering-model.md) モジュールを使用した場合:

1. **Train Clustering Model (クラスタリング モデルのトレーニング)** モジュールを右クリックします。

2. **[可視化]** を選択します。

### <a name="tips-for-generating-the-best-clustering-model"></a>最適なクラスタリング モデルを生成するためのヒント  

クラスタリング中に使用される "*シード*" プロセスは、モデルに大きな影響を与える可能性があることがわかっています。 シードとは、潜在的な重心へのポイントの初期配置を意味します。
 
たとえば、データセットに多数の異常値が含まれており、クラスターをシードするために異常値が選択されている場合、そのクラスターに適合する他のデータ ポイントは存在せず、クラスターがシングルトンになる可能性があります。 つまり、ポイントが 1 つのみの可能性があります。  
  
この問題を回避するには、いくつかの方法があります。  
  
-   重心の数を変更して、複数のシード値を試します。  
  
-   メトリックを変えるか、さらに反復処理して、複数のモデルを作成します。  
  
一般に、クラスタリング モデルでは、どのような構成でもローカルで最適化された一連のクラスターが生成される可能性があります。 つまり、モデルから返される一連のクラスターは現在のデータ ポイントのみに適合し、他のデータに一般化することはできません。 別の初期構成を使用した場合、K-Means 法では、別の優れた構成が見つかる可能性があります。 
