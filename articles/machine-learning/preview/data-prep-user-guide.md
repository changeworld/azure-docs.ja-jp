---
title: "Azure Machine Learning データ準備の使用方法に関する詳細ガイド | Microsoft Docs"
description: "このドキュメントでは、Azure ML データ準備によるデータ問題の解決に関する概要と詳細を示します"
services: machine-learning
author: euangMS
ms.author: euang
manager: lanceo
ms.reviewer: 
ms.service: machine-learning
ms.workload: data-services
ms.custom: 
ms.devlang: 
ms.topic: article
ms.date: 09/07/2017
ms.translationtype: HT
ms.sourcegitcommit: c3a2462b4ce4e1410a670624bcbcec26fd51b811
ms.openlocfilehash: 22389ba85edb119acdd21b63f2deae2d71f31373
ms.contentlocale: ja-jp
ms.lasthandoff: 09/25/2017

---
# <a name="data-preparation-user-guide"></a>データ準備ユーザー ガイド 
データ準備の操作では豊富な機能が多数用意されています。以下にその操作の最も深遠な部分について説明します。

### <a name="step-execution-history-and-caching"></a>ステップ実行、履歴、およびキャッシュ 
データ準備ステップ履歴には、パフォーマンスのために一連のキャッシュが保持されます。 ステップをクリックしてキャッシュがヒットした場合、そのステップは再実行されません。 ステップ履歴の最後に書き込みブロックがあり、そのステップを前後にフリップしても変更を加えない場合、2 回目以降は書き込みはトリガーされません。 もし 
- 書き込みブロックに変更を加えたり
- 新しい変換ブロックを追加してそれを書き込みブロックより上に移動させてキャッシュの無効化を発生させた場合、または
- 書き込みブロックより上のブロックのプロパティを変更してキャッシュの無効化を発生させたり
- サンプルの更新を選択した場合 (したがってすべてのキャッシュを無効化)

新しい書き込みが発生し、前の書き込みを上書きします。

### <a name="error-values"></a>エラー値

入力値を適切に処理できないために、その値のデータ変換が失敗することがあります。 たとえば、強制型変換操作のために、指定されたターゲットの型に入力文字列値をキャストできない場合、強制型変換が失敗します。 強制型変換操作が、文字列型の列を数値またはブール値の型に変換している可能性があります。 同様に、存在しない列を複製しようとします (列 X の削除操作を列 X の複製操作の前に移動した結果)。

このような場合は、データ準備により**エラー値**が出力として生成されます。 エラー値は、前の操作が指定された値のために失敗したことを示します。 内部的には、これらは第 1 位の値の型として扱われますが、それが存在していても列の根本的な型は変更されず、列全体がエラー値から構成されている場合でも変更されません。

エラー値の識別は簡単です。 赤色で強調表示され、"Error" と示されます。 エラーの理由を特定するには、エラー値の上にマウスを移動すると、エラーの説明テキストが表示されます。

エラー値が反映されます。 エラー値が発生すると、多くの場合、大部分の操作を通じてエラーとして伝播されます。 ただし、これらを削除または置換する方法として、現在以下の 3 つがあります。

1) *Views\\Home\\AllDates.cshtml*
    -  列を右クリックして、*[Replace Error Values] (エラー値の置換)* を選択します。 続いて、列で見つかったエラー値ごとに置換値を選択できます。

2) Remove
    - データ準備には、エラー値を保持または削除するための対話型のフィルターが用意されています。
    - 列を右クリックして、*[列フィルター]* を選択します。 エラー値を保持または削除するには、*"is error"* または *"is not error"* の条件を含む条件文を作成します。

3) Python の式を使用して、条件付きでエラー値を処理します。 詳細については、[Python の拡張機能に関するセクション](data-prep-python-extensibility-overview.md)に関する記事を参照してください。

### <a name="sampling"></a>サンプリング
データ ソース ファイルは、ローカル ファイル システムまたはリモートの場所にある 1 つまたは複数のソースから生データを取得します。 サンプル ブロックを使用すると、サンプルを生成することによって、データのサブセットを操作するかどうかを指定できます。 大規模なデータセットではなくデータのサンプルを操作すると、多くの場合、後の手順で操作を実行するときにパフォーマンスが向上します。

データ ソース ファイルごとに、複数のサンプルを生成および保存できます。 ただし、アクティブなサンプルとして設定できるサンプルは 1 つだけです。 データ ソース ウィザードで、またはサンプル ブロックを編集することにより、サンプルを作成、編集、または削除できます。 データ ソースを参照するすべてのデータ準備ファイルは本質的に、データ ソース ファイルで指定されたサンプルを使用します。

さまざまな構成可能なパラメーターのそれぞれで使用できるサンプリング方法は多数あります。

#### <a name="top"></a>Top (上位)
この方法は、ローカル ファイルまたはリモート ファイルのどちらかに適用できます。 最初の N 行 (カウントで指定) をデータ ソースに取得します。

#### <a name="random-n"></a>ランダム N 
この方法は、ローカル ファイルにのみ適用できます。 ランダムな N 行 (カウントで指定) をデータ ソースに取得します。 特定のシードを指定して、カウントも同じであれば同じサンプルが生成されるように確保できます。

#### <a name="random-"></a>ランダム % 
この方法は、ローカル ファイルまたはリモート ファイルのどちらかに適用できます。 どちらの場合でも、ランダム N 方法と同様に、確率とシードを指定する必要があります。

リモート ファイルのサンプルについては、追加のパラメーターを指定する必要があります。

- サンプル ジェネレーター 
  - サンプルの生成に使用する Spark クラスターまたはリモート Docker コンピューティング ターゲットを選択します。 プロジェクト用のコンピューティング ターゲットをこの一覧に表示する前に、作成しておく必要があります。 [Azure Machine Learning での GPU の使用方法](how-to-use-gpu.md)の「新しい計算ターゲットの作成」の手順に従って、コンピューティング ターゲットを作成します。
- サンプル記憶域 
  - リモートのサンプルを格納する中間記憶域の場所を指定します。 このパスは、入力ファイルの場所とは別のディレクトリにする必要があります。

#### <a name="full-file"></a>完全なファイル 
この方法は、ローカル ファイルにのみ適用でき、完全なファイルをデータ ソースに取得します。 ファイルが大きすぎる場合は、このオプションは、アプリでの以降の処理速度が低下する可能性があり、別のサンプリング方法を使用したほうが適切なことがあります。


### <a name="forking-merging-and-appending"></a>フォーク、マージ、および追加

フィルターをデータセットに適用すると、この操作によってデータは 2 つの結果セットに分割されます。一方のセットは、フィルターを通ったレコードを表し、もう一方のセットは通らなかったレコードを表します。 どちらの場合も、ユーザーは表示する結果セットを選択できます。 ユーザーは、他方のデータセットを破棄することも、新しいデータフローに配置することもできます。 後者のオプションを*フォーク*と呼びます。

フォークするには、列を選択し、右クリックして、[フィルター] 列を選択します。
- [I Want To] (目的の操作) の下で、*[Keep Rows] (行の保持)* を選択して、フィルターを通った結果セットを表示するか、*[Remove Rows] (行の削除)* を選択して、通らなかったセットを表示します。
- [Conditions] (条件) の後で、*[Create Dataflow Containing the Filtered Out Rows] (フィルターで除去された行を含むデータフローの作成)* を選択して、表示されない結果セットを新しいデータフローにフォークします。


この手法は多くの場合、追加の準備を必要とするデータのセットを分割します。 フォークしたデータ セットをラングリングした後、そのデータを元のデータフロー内の結果セットとマージすることが一般的です。 "マージ" ("フォーク" 操作の逆) を実行するには、次のいずれかのアクションを使用します。
- *行の追加*。 2 つ以上のデータフローを垂直方向 (行方向) にマージします。 
- *列の追加*。 2 つ以上のデータフローを水平方向 (列方向) にマージします。


>[!NOTE]
>列の追加は、列の競合が発生すると失敗します。


マージ操作の後、1 つまたは複数のデータフローがソース データフローで参照されます。 データ準備は、アプリの右下、ステップの一覧の下に通知を表示します。


参照先のデータフローを操作すると、参照先のデータフローから使用されるサンプルを更新するように親データフローが要求されます。 その場合、確認のダイアログ ボックスが、右下のデータフロー参照通知に置き換わります。 そのダイアログ ボックスには、すべての依存関係データフローへの変更を同期するためにデータフローを更新する必要があると表示されます。

### <a name="list-of-appendices"></a>付録の一覧 
[付録 2 - サポートされるデータ ソース](data-prep-appendix2-supported-data-sources.md)  
[付録 3 - サポートされる変換](data-prep-appendix3-supported-transforms.md)  
[付録 4 - サポートされるインスペクター](data-prep-appendix4-supported-inspectors.md)  
[付録 5 - サポートされる変換先](data-prep-appendix5-supported-destinations.md)  
[付録 6 - Python のフィルター式のサンプル](data-prep-appendix6-sample-filter-expressions-python.md)  
[付録 7 - Python の変換データ フロー式のサンプル](data-prep-appendix7-sample-transform-data-flow-python.md)  
[付録 8 - Python のデータ ソースのサンプル](data-prep-appendix8-sample-source-connections-python.md)  
[付録 9 - Python の変換先接続のサンプル](data-prep-appendix9-sample-destination-connections-python.md)  
[付録 10 - Python の列変換のサンプル](data-prep-appendix10-sample-custom-column-transforms-python.md)  

