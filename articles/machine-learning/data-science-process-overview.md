---
title: "Team Data Science Process ライフサイクル | Microsoft Docs"
description: "データ サイエンス プロジェクトを構成するための、ライフサイクルのステップとコンポーネントについて説明します。"
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: b1f677bb-eef5-4acb-9b3b-8a5819fb0e78
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 02/08/2017
ms.author: bradsev;hangzh;gokuma
translationtype: Human Translation
ms.sourcegitcommit: 1796f7a7cd174d7ed6582878d72c59995aac41cb
ms.openlocfilehash: 995ba0dc3ffd2bc78625db7d1176ca0d5e1611a0
ms.lasthandoff: 02/08/2017


---
# <a name="team-data-science-process-lifecycle"></a>Team Data Science Process ライフサイクル
Team Data Science Process (TDSP) には、データ サイエンス プロジェクトの開発プロセスを構築するうえで利用できる、お勧めのラフサイクルが用意されています。 このライフサイクルは、プロジェクトを実行する際に、その開始から終了までにわたって進められる通常のステップを大まかにまとめたものです。 [CRISP-DM](https://wikipedia.org/wiki/Cross_Industry_Standard_Process_for_Data_Mining)、[KDD](https://wikipedia.org/wiki/Data_mining#Process)、所属する組織独自のカスタム プロセスなど、別のデータ サイエンス ライフサイクルを利用している場合は、それらの開発ライフサイクルにタスクベースの TDSP を組み込んで使用することもできます。 

このライフサイクルは、インテリジェント アプリケーションに付属することを意図したデータ サイエンス プロジェクト向けに設計されています。 このようなアプリケーションでは、機械学習モデルや人工知能モデルをデプロイして予測分析に使用します。 このプロセスは、探索的データ サイエンス プロジェクトや、アドホックまたはオン/オフ分析プロジェクトに利用しても効果的ですが、そのような場合、ここで説明する一部のステップは不要になることがあります。    

次の図は、**Team Data Science Process ライフサイクル**を視覚的に表したものです。 

![TDSP ライフサイクル](./media/data-science-process-overview/tdsp-lifecycle.png) 

TDSP ライフサイクルは、繰り返し実行される&5; つの主なステージで構成されています。 チェックの内容は次のとおりです

* **ビジネスの把握**
* **データの取得と理解**
* **モデリング**
* **デプロイ**
* **顧客による受け入れ**

各ステージで、以下のような情報を提供します。

* **目標**: 項目別にまとめられた具体的な目標。
* **方法**: 具体的な課題についての概説と、その達成方法に関するガイダンス。
* **アーティファクト**: 成果物と、その生成方法に関するサポート。

## <a name="1-business-understanding"></a>1.ビジネスの把握
### <a name="goals"></a>目標
* **モデル ターゲット**としての機能を果たし、その関連メトリックがプロジェクトの成功を評価するために使用される変数を、**主要な変数**に指定する。
* 必要に応じてビジネスまたはその他のソースからアクセスできるデータ ソースとして、関連性のある**データ ソース**を特定する。

### <a name="how-to-do-it"></a>方法
このステージでは、以下に示す&2; つの主な課題に取り組みます。 

* **目標を定義する**: 顧客およびその他の利害関係者と連携し、ビジネス上の問題を把握し、特定します。 データ サイエンス手法のターゲットにできるような、ビジネスの目標を定義付ける質問を考案します。
* **データ ソースを特定する**: プロジェクトの目標を定義付ける質問に対して答えを出すために利用できる関連データを見つけます。

#### <a name="11-define-objectives"></a>1.1 目標を定義する
1. このステップの中心となる目標は、分析によって予測する必要がある、主要な**ビジネス変数**を特定することです。 この変数は**モデル ターゲット**と呼ばれ、これに関連付けられているメトリックはプロジェクトの成功を評価するために使用されます。 たとえば売上予測や、ある注文が不正な注文である確率などが、このようなターゲットとなります。
2. 関連性があり、具体的かつ明確な "鋭い" 質問の問いかけと改善を行うことで、**プロジェクトの目標**を定義します。 データ サイエンスは、名前と数字を使ってこのような質問に回答するプロセスです。 "*質問を選ぶときは、あらゆる疑問に数字か名前で答えてくれる賢者がいたとして、その賢者に自分が話し掛けていることを想像してください*"。 その他のガイダンスについては、ブログ「[How to do Data Science (データ サイエンスを実行する方法)](https://blogs.technet.microsoft.com/machinelearning/2016/03/28/how-to-do-data-science/)」の「**Ask a Sharp Question (鋭い質問をする)**」セクションを参照してください。   データ サイエンスや機械学習は、一般的には以下の&5; 種類の質問に回答するために使用されます。
   * どのくらいの量または数か  (回帰)
   * どのカテゴリか  (分類)
   * どのグループか  (クラスタリング)
   * 異常か (異常の検出)
   * どの選択肢を選ぶべきか  (推奨)
3. メンバーの役割と責任を定めることにより、**プロジェクト チーム**を定義します。 見つかる情報の増加に伴い繰り返し実行する、大まかなマイルストーン プランを作成します。  
4. **成功のメトリックを定義します**。 例: 顧客離れを低減するためのプロモーションを提供できるように、3 か月間のプロジェクトが終了するまでに顧客離れの予測精度 X% を達成する。 **SMART (スマート)** なメトリックを定義する必要があります。 
   * **S**pecific (具体的) 
   * **M**easurable (測定可能)
   * **A**chievable (達成可能) 
   * **R**elevant (関連性がある) 
   * **T**ime-bound (期限付き) 

#### <a name="12-identify-data-sources"></a>1.2 データ ソースを特定する
鋭い質問への既知の回答例を含むデータ ソースを特定します。 以下のようなデータを探します。

* 質問に対して**関連性のある**データ。 ターゲットの測定値と、ターゲットに関連する特徴があるか。
* モデル ターゲットの**正確な測定値**であるデータと、対象とする特徴。

たとえば、既存のシステムで問題を解決し、プロジェクトの目標を達成するために、従来とは異なる種類のデータを収集、記録しなければならないことはよくあります。 このような場合は、外部のデータ ソースを探すか、より新しいデータを収集するようにシステムを更新することをお勧めします。

### <a name="artifacts"></a>アーティファクト
このステージでの成果物を以下に示します。

* [**憲章ドキュメント**](https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Project/Charter.md): TDSP プロジェクト構造定義で標準テンプレートが提供されています。 これは、新しいデータの検出やビジネス要件の変更に応じてプロジェクト全体で更新される、常に最新のドキュメントです。 検出プロセスの進行に合わせてこのドキュメントに詳細を追加し、更新を繰り返すことが重要です。 変更を加える際は、顧客およびその他の利害関係者が常に関与するようにし、変更の理由を明確に伝えます。  
* [**データ ソース**](https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/DataReport/Data%20Defintion.md#raw-data-sources): これは、TDSP プロジェクト構造に含まれるデータ レポートの一部です。 生データのソースが記載されています。 後のステージで、分析環境にデータを移動するスクリプトなどの詳細を追加します。  
* [**データ**](https://github.com/Azure/Azure-TDSP-ProjectTemplate/tree/master/Docs/DataDictionaries): このドキュメントには、質問への回答に使用されるデータについての説明とスキーマ (データの種類や、検証ルールがある場合はその情報) が記載されます。 エンティティ関係を示す図または説明がある場合は、それも含まれます。

## <a name="2-data-acquisition-and-understanding"></a>2.データの取得と理解
### <a name="goals"></a>目標
* ターゲット変数との関係が把握されているクリーンな高品質データセットを、すぐにモデル化できる状態で分析環境に配置する。
* データを定期的に更新およびスコア付けするデータ パイプラインのソリューション アーキテクチャを開発する。

### <a name="how-to-do-it"></a>方法
このステージでは、以下に示す&3; つの主な課題に取り組みます。

* ターゲットの分析環境に**データを取り込む**。
* データの品質が質問に回答するのに十分かどうかを判断するために、**データを調べる**。 
* 新しいデータや定期的に更新されるデータをスコア付けするための**データ パイプラインを設定する**。

#### <a name="21-ingest-the-data"></a>2.1 データを取り込む
トレーニングや予測などの分析操作が実行されるターゲットの場所に、ソースの場所からデータを移動するプロセスを設定します。 この設定を各種 Azure データ サービスで行う方法についての技術的な詳細とオプションは、「[分析用のストレージ環境にデータを読み込む](machine-learning-data-science-ingest-data.md)」を参照してください。 

#### <a name="22-explore-the-data"></a>2.2 データを調べる
モデルのトレーニングを行う前に、データを正しく理解する必要があります。 実際のデータセットは、ノイズが多かったり、値が欠落していたり、その他の不一致が数多く見つかったりすることがよくあります。 データの要約と視覚化を行うことで、データをモデリングに使用する前に、そのデータの品質を監査し、処理に必要な情報を得ることができます。 データのクリーニングに関するガイダンスについては、「[機械学習を強化するためのデータを準備するタスク](machine-learning-data-science-prepare-data.md)」を参照してください。 このプロセスは、通常は繰り返し実行されます。 

TDSP には、データの視覚化と概要レポートの準備に役立つ、[IDEAR](https://github.com/Azure/Azure-TDSP-Utilities/blob/master/DataScienceUtilities/DataReport-Utils) と呼ばれる自動化されたユーティリティが用意されています。 最初は IDEAR を使ってデータを調べることで、コーディングを行わずに対話形式でデータへの理解を深めてから、データの調査および視覚化用のカスタム コードの作成に進むことをお勧めします。 

クリーニング済みデータの品質が十分であると確認できたら、次のステップは、ターゲットに適した予測モデルを選択して開発できるように、データに固有のパターンをよく理解することです。 データとターゲットのつながりの程度や、次のモデリング ステップに進むうえで十分なデータがあるかどうかを示す証拠を探します。 このプロセスも、通常は繰り返し実行されます。 場合によっては、前のステージで最初に特定したデータセットを強化するために、より正確なデータや関連性の高いデータを持つ新しいデータ ソースを探すことが必要になります。  

#### <a name="23-set-up-a-data-pipeline"></a>2.3 データ パイプラインを設定する
最初に行うデータの取り込みとクリーニングに加え、通常は、新しいデータをスコア付けするプロセスやデータを定期的に更新するプロセスを、継続的な学習プロセスの一部として設定する必要があります。 この設定は、データ パイプラインまたはワークフローの設定によって行うことができます。 [こちらの例](machine-learning-data-science-move-sql-azure-adf.md)では、[Azure Data Factory](https://azure.microsoft.com/services/data-factory/) でパイプラインを設定する方法について説明しています。 データ パイプラインのソリューション アーキテクチャの開発は、このステージで行います。 また、以降のデータ サイエンス プロジェクトのステージでも、パイプラインの開発は並行して行います。 パイプラインは、ビジネス ニーズと、このソリューションの統合先とする既存システムの制約に応じて、バッチベース、ストリーミング/リアルタイム、ハイブリッドのいずれかに決まります。 

### <a name="artifacts"></a>アーティファクト
このステージでの成果物を以下に示します。

* [**データ品質レポート**](https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/DataReport/DataSummaryReport.md): このレポートには、データの概要、各属性とターゲットの関係、変数のランクなどが含まれます。TDSP の一部として提供される [IDEAR](https://github.com/Azure/Azure-TDSP-Utilities/blob/master/DataScienceUtilities/DataReport-Utils) ツールを使用すると、CSV ファイルやリレーショナル テーブルなどの任意の表形式データセットで、このレポートをすばやく生成できます。 
* **ソリューション アーキテクチャ**: これは、モデルの構築後に、新しいデータでのスコア付けや予測の実行に使用されるデータ パイプラインのダイアグラムまたは説明です。 また、新しいデータに基づきモデルを再トレーニングするためのパイプラインも、これに含まれます。 TDSP ディレクトリ構造テンプレートを使用する場合、ドキュメントは[こちらのディレクトリ](https://github.com/Azure/Azure-TDSP-ProjectTemplate/tree/master/Docs/Project)に格納されています。
* **チェックポイント判定**: 特徴エンジニアリングとモデルの構築を本格的に開始する前に、プロジェクトを再評価し、そのプロジェクトを続行するために期待される十分な値があるかどうかを判断できます。 たとえば、先に進む準備ができている、さらに多くのデータを収集する必要がある、質問に回答するためのデータが存在しないためプロジェクトを破棄するといった判断ができます。

## <a name="3-modeling"></a>手順&3;.モデリング
### <a name="goals"></a>目標
* 機械学習モデルに最適なデータの特徴。
* 最も正確にターゲットを予測でき、有益な情報を提供する ML モデル。
* 運用環境に適した ML モデル。

### <a name="how-to-do-it"></a>方法
このステージでは、以下に示す&3; つの主な課題に取り組みます。

* **特徴エンジニアリング**: モデルをトレーニングしやすくするために生データからデータの特徴を作成します。
* **モデル トレーニング**: 成功のメトリックを比較することで、最も正確に質問に回答できるモデルを見つけます。
* モデルが**運用環境に適している**かどうかを判断する。

#### <a name="31-feature-engineering"></a>3.1 特徴エンジニアリング
特徴エンジニアリングでは、分析に使用する特徴を作成するために、未加工の変数の追加、集計、変換を行います。 何がモデルの推進要因となっているかを把握したい場合、それぞれの特徴の相互関係と、それらの特徴が機械学習アルゴリズムでどのように使用されるかを理解する必要があります。 このステップでは、特定分野の専門知識とデータの調査ステップから得られた知見を創造的に組み合わせる必要があります。 これは、関連性の低い変数が増えすぎないように注意しながら、情報量の多い変数を見つけて追加する作業であり、バランス感覚が求められます。 情報量の多い変数は結果の改善に貢献しますが、関連性の低い変数は不要なノイズがモデルに混入する原因となります。 また、これらの特徴は、スコア付け中に取得した新しいデータがあれば、そのデータに対して生成する必要もあります。 そのため、これらの特徴の生成は、スコア付け時に使用できるデータのみに基づいて行われます。 各種 Azure データ テクノロジを利用して特徴エンジニアリングを行う場合の技術的なガイダンスについては、[データ サイエンス プロセスにおける特徴エンジニアリング](machine-learning-data-science-create-features.md)に関するページを参照してください。 

#### <a name="32-model-training"></a>3.2 モデル トレーニング
回答しようとしている質問の種類に応じて、数多くのモデリング アルゴリズムが利用できます。 アルゴリズムの選択に関するガイダンスについては、「[Microsoft Azure Machine Learning のアルゴリズムの選択方法](machine-learning-algorithm-choice.md)」を参照してください。 これは Azure Machine Learning に関する記事ですが、記載されているガイダンスはその他の ML フレームワークにも活用できます。 

モデル トレーニングのプロセスには、以下のステップが含まれます。 

* 入力データを、モデリング用のトレーニング データセットとテスト データセットにランダムに分割する。
* トレーニング データセットを使用してモデルを構築する。
* 競合する一連の機械学習アルゴリズムを、現状のデータで目的の質問に回答できるよう調整された、各種の関連するチューニング パラメーター (パラメーター スイープと呼ばれる) と共に (トレーニング データセットとテスト データセットで) 評価する。
* 別々の方法での成功のメトリックを比較し、質問に回答するための "最適" なソリューションを判定する。

> [!NOTE]
> **漏えいの防止**: トレーニング データセットの外部のデータを含めることでデータ漏えいが発生する可能性があり、それによってモデルまたは機械学習アルゴリズムが非現実的なほど良好な予測を行うことがあります。 信じられないほど良好な予測結果が得られた場合に、データ サイエンティストが不安を感じる理由として代表的なのが、この漏えいです。 これらの依存関係は検出しにくい場合があります。 この問題を回避するには、多くの場合、分析データセットの構築、モデルの作成、精度の評価を繰り返し行うことが必要になります。 
> 
> 

Microsoft では、複数のアルゴリズムとパラメーター スイープを介して実行し、ベースライン モデルを生成することができる、[Automated Modeling and Reporting ツール](https://github.com/Azure/Azure-TDSP-Utilities/blob/master/DataScienceUtilities/Modeling)を TDSP と共に提供しています。 このツールでは、変数の重要性を含む、各モデルおよびパラメーターの組み合わせによるパフォーマンスを要約した、ベースライン モデリング レポートも生成されます。 特徴エンジニアリングをさらに促進することができるため、このプロセスも繰り返し実行されます。 

### <a name="artifacts"></a>アーティファクト
このステージで生成されるアーティファクトには、以下のものが含まれます。

* [**特徴セット**](https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/DataReport/Data%20Defintion.md#feature-sets): モデリング用に作成された特徴は、データ定義レポートの「Feature Set (特徴セット)」セクションに記載されます。 これには、特徴を生成するコードへのポインターと、特徴の生成方法についての説明が含まれます。
* [**モデリング レポート**](https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Model/Model%201/Model%20Report.md): テストした各モデルに対して、指定された TDSP テンプレートに準拠する標準レポートが生成されます。
* **チェックポイント判定**: モデルのパフォーマンスが、実稼働システムにデプロイするのに十分かどうかを評価します。 主な考慮事項の一部を以下に示します。
  * テスト データから判断して、質問に対するモデルの回答に十分な確実性があるか。 
  * 任意の代替手法 (追加データを収集する、特徴エンジニアリングをさらに実行する、他のアルゴリズムで実験する) を試す必要があるか。

## <a name="4-deployment"></a>4.デプロイ
### <a name="goal"></a>目標
* モデルとパイプラインは、最終ユーザーによる受け入れに向けて、運用環境または運用環境に似た環境にデプロイされます。 

### <a name="how-to-do-it"></a>方法
このステージでは、以下に示す主な課題に取り組みます。

* **モデルの運用化**: モデルとパイプラインを、アプリケーションで利用できるように運用環境または運用環境に似た環境にデプロイします。

#### <a name="41-operationalize-a-model"></a>4.1 モデルの運用化
うまく機能する一連のモデルが得られたら、他のアプリケーションから利用できるように、それらのモデルを運用できる状態にします。 予測は、ビジネス要件に応じてリアルタイムまたはバッチ処理で行われます。 モデルを運用できる状態にするためには、オンライン Web サイト、スプレッドシート、ダッシュボード、基幹業務アプリケーション、バックエンド アプリケーションなどの各種のアプリケーションから利用しやすいようオープン API インターフェイスでそのモデルを公開する必要があります。 Azure Machine Learning Web サービスによるモデルの運用化の例については、「[Azure Machine Learning Web サービスをデプロイする](machine-learning-publish-a-machine-learning-web-service.md)」を参照してください。 また、テレメトリと監視をデプロイ済みの運用モデルとデータ パイプラインに組み込み、システム ステータスの報告とトラブルシューティングに活用することもお勧めします。  

### <a name="artifacts"></a>アーティファクト
* システムの正常性と主なメトリックについてのステータス ダッシュボード。
* デプロイの詳細を含む最終的なモデリング レポート。
* 最終的なソリューション アーキテクチャ ドキュメント。

## <a name="5-customer-acceptance"></a>5.顧客による受け入れ
### <a name="goal"></a>目標
* **プロジェクトの成果物を完成させる**: パイプライン、モデル、およびそれらの運用環境でのデプロイが顧客の目標を満たしていることを確認します。

### <a name="how-to-do-it"></a>方法
このステージでは、以下に示す&3; つの主な課題に取り組みます。

* **システムの検証**: デプロイ済みのモデルとパイプラインが顧客のニーズを満たしていることを確認します。
* **プロジェクトのハンドオフ**: 運用環境でシステムを運用する組織にハンドオフします。

顧客は、システムを運用環境にデプロイして独自のクライアント アプリケーションで利用できるようにするため、そのシステムがビジネス ニーズを満たし、許容可能な精度で質問に回答できるかどうかを検証します。 すべてのドキュメントに対して最終処理とレビューが行われます。 運用を担う組織へのプロジェクトのハンドオフが、これで完了します。 この場合の組織とは、たとえば運用環境でのシステム運用を担当する IT 部門、顧客のデータ サイエンス チーム、顧客の代理業者などです。 

### <a name="artifacts"></a>アーティファクト
この最終ステージで生成される主なアーティファクトは、[**プロジェクトの最終レポート**](https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Project/Exit%20Report.md)です。 これはプロジェクトの技術レポートであり、システムの学習と運用に役立つプロジェクトのすべての詳細が含まれます。 TDSP によって提供されている[テンプレート](https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Project/Exit%20Report.md)は、そのまま使用することも、クライアント固有のニーズに合わせてカスタマイズすることもできます。 

## <a name="summary"></a>概要
[Team Data Science Process ライフサイクル](http://aka.ms/datascienceprocess)は、繰り返し行う一連のステップとしてモデル化されており、予測モデルを使用するために必要な作業のガイダンスとして役立ちます。 これらのモデルは運用環境にデプロイして、インテリジェントなアプリケーションの構築に活用できます。 このプロセス ライフサイクルの目的は、データ サイエンス プロジェクトを契約上の明確な終着点へと継続的に導くことです。 データ サイエンスとは調査と探索の作業ですが、標準化されたテンプレートで明確に定義した一連のアーティファクトを利用し、その内容をチームと顧客に対してはっきり伝えることができれば、誤解が生じる危険を回避し、複雑なデータ サイエンス プロジェクトをより高い確率で成功に導くことができます。

## <a name="next-steps"></a>次のステップ
また、 **特定のシナリオ** のプロセスに伴うすべての段階をリハーサル的に最初から最後まで実証することも可能です。 「[Team Data Science Process のチュートリアル](data-science-process-walkthroughs.md)」に、これらのチュートリアルが簡単な説明と共にリンク付きで紹介されています。


