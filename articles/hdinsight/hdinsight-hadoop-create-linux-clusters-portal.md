---
title: Web ブラウザーを使用して Apache Hadoop クラスターを作成する - Azure HDInsight
description: Web ブラウザーと Azure portal を使用して、Linux 上に HDInsight 用の Apache Hadoop、Apache HBase、Apache Storm、または Apache Spark クラスターを作成する方法について説明します。
author: hrasheed-msft
ms.author: hrasheed
ms.reviewer: jasonh
ms.service: hdinsight
ms.custom: hdinsightactive
ms.topic: conceptual
ms.date: 11/13/2019
ms.openlocfilehash: 820ddb8d06cfd2aac2b053305f23ad330e4fd7c3
ms.sourcegitcommit: d6b68b907e5158b451239e4c09bb55eccb5fef89
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 11/20/2019
ms.locfileid: "74215912"
---
# <a name="create-linux-based-clusters-in-hdinsight-by-using-the-azure-portal"></a>Azure portal を使用して HDInsight で Linux ベースのクラスターを作成する

[!INCLUDE [selector](../../includes/hdinsight-create-linux-cluster-selector.md)]

Azure Portal は、Microsoft Azure クラウドでホストされるサービスやリソースの Web ベースの管理ツールです。 この記事では、ポータルを使用して Linux ベースの Azure HDInsight クラスターを作成する方法について説明します。

[!INCLUDE [delete-cluster-warning](../../includes/hdinsight-delete-cluster-warning.md)]

## <a name="prerequisites"></a>前提条件

* **Azure サブスクリプション**。 「[How to get Azure Free trial for testing Hadoop in HDInsight (HDInsight で Hadoop をテストするために Azure の無料試用版を入手する方法)](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)」をご覧ください。
* **最新の Web ブラウザー**。 Azure portal では、HTML5 と JavaScript が使用されます。 古い Web ブラウザーでは正常に機能しない可能性があります。

## <a name="create-clusters"></a>クラスターの作成

Azure Portal には、ほとんどのクラスターのプロパティが公開されます。 Azure Resource Manager テンプレートを使用すると、多くの詳細を非表示にできます。 詳しくは、「[Resource Manager テンプレートを使用して HDInsight で Apache Hadoop クラスターを作成する](hdinsight-hadoop-create-linux-clusters-arm-templates.md)」をご覧ください。

[!INCLUDE [secure-transfer-enabled-storage-account](../../includes/hdinsight-secure-transfer.md)]

1. [Azure Portal](https://portal.azure.com) にサインインします。

1. 左側のメニューから、 **[+ リソースの作成]**  >   **[Analytics]**  >  **[Azure HDInsight]** に移動します。

    ![Azure portal で新しいクラスターを作成する](./media/hdinsight-hadoop-create-linux-clusters-portal/hdinsight-create-cluster.png "Azure Portal での新しいクラスターの作成")

1. **[HDInsight クラスターの作成]** ページで、 **[Go to classic create experience]\(従来の作成エクスペリエンスに移動\)** を選択します。

    ![従来の作成エクスペリエンスに移動](./media/hdinsight-hadoop-create-linux-clusters-portal/azure-portal-cluster-create-classic.png)

1. **[HDInsight]** ページで、 **[カスタム (サイズ、設定、アプリ)]** を選択します。

1. **[1 基本]** を選択します。 そして、次の情報を入力します。

    |プロパティ |説明 |
    |---|---|
    |クラスター名|この名前はグローバルに一意である必要があります。|
    |Subscription|ドロップダウン リストから、このクラスターに使用する Azure サブスクリプションを選択します。|
    |クラスターの種類|作成するクラスターの種類を選択します。 たとえば、Hadoop や Apache Spark です。 **[オペレーティング システム]** は **[Linux]** になります。 次に、クラスターの種類のバージョンを選択します。 どれを選択すべきかわからない場合は、既定のバージョンを使用します。 詳細については、「 [HDInsight クラスターのバージョン](hdinsight-component-versioning.md)」をご覧ください。|
    |クラスター ログイン ユーザー名|ユーザー名を指定します。既定値は **admin** です。|
    |クラスター ログイン パスワード|パスワードを指定します。|
    |Secure Shell (SSH) ユーザー名|既定値は **sshuser** です。 SSH パスワードを前に指定した管理者パスワードと同じにする場合は、 **[SSH にクラスター ログイン パスワードを使用する]** チェック ボックスをオンします。 そうでない場合は、SSH ユーザーを認証するための **[パスワード]** または **[公開キー]** を指定します。 公開キーを使用することをお勧めします。 下部にある **[選択]** を選択して、資格情報の構成を保存します。  詳しくは、「[SSH を使用して HDInsight (Apache Hadoop) に接続する](hdinsight-hadoop-linux-use-ssh-unix.md)」をご覧ください。|
    |Resource group|新しいリソース グループを作成するか、既存のリソース グループを使用するかを指定します。|
    |Location|クラスターを作成するデータセンターを指定します。|

    ![HDInsight でのクラスター作成の基本](./media/hdinsight-hadoop-create-linux-clusters-portal/hdinsight-create-cluster-basics.png "Azure Portal での新しいクラスターの作成")

    > [!IMPORTANT]  
    > HDInsight クラスターにはさまざまな種類があります。 それぞれに対応するワークロードやテクノロジがあり、それに合わせてクラスターが調整されます。 複数の種類を組み合わせたクラスターを作成する方法はサポートされていません。 たとえば、Storm と HBase を 1 つのクラスターにするような場合です。

    **[次へ]** を選択して、次のページに進みます。

1. **[2 セキュリティとネットワーク]** で、表示されているドロップダウン メニューを使用してクラスターを仮想ネットワークに接続できます。 クラスターを仮想ネットワークに配置する場合は、Azure Virtual Network とサブネットを選択します。 仮想ネットワークでの HDInsight の使用については、[Azure HDInsight クラスター用の仮想ネットワーク デプロイの計画](hdinsight-plan-virtual-network-deployment.md)に関するページを参照してください。 その記事には、仮想ネットワークの具体的な構成要件が含まれます。

    **Enterprise セキュリティ パッケージ**を使用する場合は、「[Azure Active Directory Domain Services を使用して、Enterprise セキュリティ パッケージで HDInsight クラスターを構成する](https://docs.microsoft.com/azure/hdinsight/domain-joined/apache-domain-joined-configure-using-azure-adds)」の手順に従うこともできます。

    **[次へ]** を選択して、次のページに進みます。

1. **[3 ストレージ]** の **[ストレージ アカウントの設定]** で、既定のストレージとして Azure Storage と Azure Data Lake Storage のどちらを使用するかを指定します。 詳細については、後の表を参照してください。

    | プライマリ ストレージの種類 | 説明 |
    |------------------|-------------|
    | Azure Storage   |  * **[選択方法]** では、自分の Azure サブスクリプションの一部であるストレージ アカウントを指定する場合は、 **[個人用サブスクリプション]** を選択します。 次に、ストレージ アカウントを選択します。 それ以外の場合は、 **[アクセス キー]** を選択します。 次に、自分の Azure サブスクリプションの外部から選択するストレージ アカウントの情報を指定します。</br></br> * **[既定のコンテナー]** では、ポータルによって示された既定のコンテナー名を使用するか、独自の名前を指定します。</br></br> * Azure Blob ストレージが既定のストレージである場合は、 **[追加のストレージ アカウント]** を選択して、クラスターに関連付ける追加のストレージ アカウントを指定することもできます。 **[Azure Storage キー]** では、 **[ストレージ キーの追加]** を選択します。 その後、自分の Azure サブスクリプションまたは他のサブスクリプションから、ストレージ アカウントを指定できます。 ストレージ アカウントのアクセス キーを指定します。</br></br> * BLOB ストレージが既定のストレージである場合は、 **[Data Lake Storage access]\(Data Lake Storage アクセス\)** を選択し、追加のストレージとして Azure Data Lake Storage を指定することもできます。 詳細については、「[クイック スタート: HDInsight のクラスターを設定する](../storage/data-lake-storage/quickstart-create-connect-hdi-cluster.md)」をご覧ください。</li></ul> |
    | Azure Data Lake Storage | **[Azure Data Lake Storage Gen1]** または **[Azure Data Lake Storage Gen2]** を選択します。 その後、「[クイック スタート:HDInsight のクラスターを設定する](../storage/data-lake-storage/quickstart-create-connect-hdi-cluster.md)」の手順を参照してください。 |

    **metastore の設定 (省略可能)**

    必要に応じて、クラスターに関連付けられた Apache Hive と Apache Oozie のメタデータを保存するための SQL データベースを指定します。 **[Hive 用の SQL データベースを選択する]** で、SQL データベースを選択します。 次に、データベースのユーザー名とパスワードを指定します。 以上の手順を Oozie メタデータについても行います。

    メタストアに Azure SQL データベースを使用する場合の考慮事項は次のとおりです。
    * メタストアに使用される Azure SQL データベースは、Azure HDInsight などの他の Azure サービスに接続できる必要があります。 Azure SQL データベース ダッシュボードの右側で、サーバー名を選択します。 これは SQL データベース インスタンスが実行されているサーバーです。 サーバー ビューに移動した後、 **[構成]** を選択します。 次に、 **[Azure サービス]** で **[はい]** を選択します。 次に、 **[保存]** を選択します。
    * メタストアを作成するとき、データベース名にダッシュやハイフンを使用しないでください。 これらの文字が含まれると、クラスター作成プロセスが失敗する可能性があります。

    ![HDInsight でのクラスター ストレージの作成](./media/hdinsight-hadoop-create-linux-clusters-portal/hdinsight-create-cluster-storage.png "Azure Portal での新しいクラスターの作成")

    > [!WARNING]  
    > HDInsight クラスター以外の場所で追加のストレージ アカウントを使用することはできません。

    **[次へ]** を選択して、次のページに進みます。

1. **[4 アプリケーション (オプション)]** で、必要なアプリケーションを選択します。 これらのアプリケーションは、Microsoft、独立系ソフトウェア ベンダー (ISV)、またはご自身が独自に開発できます。 詳しくは、「[クラスター作成時のアプリケーションのインストール](hdinsight-apps-install-applications.md#install-applications-during-cluster-creation)」をご覧ください。

    **[次へ]** を選択して、次のページに進みます。

1. **[5 クラスター サイズ]** に、このクラスターのために使用されるノードに関する情報が表示されます。 クラスターで必要な worker ノードの数を設定します。 クラスター実行の推定コストが表示されます。

    ![HDInsight でのクラスター ノードの作成](./media/hdinsight-hadoop-create-linux-clusters-portal/hdinsight-create-cluster-nodes.png "クラスター ノードの数を指定する")

   > [!IMPORTANT]  
   > 32 個を超えるワーカー ノードを予定している場合、コア数が 8 個以上で RAM が 14 GB 以上のサイズのヘッド ノードを選択します。 クラスターの作成時に、または作成後にクラスターのスケーリングで、ノードを計画します。
   >
   > ノードのサイズと関連コストについて詳しくは、「[Azure HDInsight の料金](https://azure.microsoft.com/pricing/details/hdinsight/)」をご覧ください。

    **[次へ]** を選択して、次のページに進みます。

1. **[6 スクリプト操作]** で、カスタム コンポーネントをインストールするようにクラスターをカスタマイズできます。 このオプションは、クラスターを作成するときに、カスタム スクリプトを使用してクラスターをカスタマイズする場合に使用します。 スクリプト アクションについて詳しくは、「[スクリプト アクションを使用して Linux ベースの HDInsight クラスターをカスタマイズする](hdinsight-hadoop-customize-cluster-linux.md)」をご覧ください。

   **[次へ]** を選択して、次のページに進みます。

1. **[7 概要]** で、これまでに入力した情報を確認します。 **[作成]** を選択します。

    ![HDInsight でのクラスター作成の概要](./media/hdinsight-hadoop-create-linux-clusters-portal/hdinsight-create-cluster-summary.png "クラスター ノードの数を指定する")

    > [!NOTE]  
    > クラスターが作成されるまで、通常は約 20 分かかります。 **[通知]** を監視して、プロビジョニング プロセスをチェックします。

1. 作成プロセスが完了したら、 **[デプロイが成功しました]** という通知から **[リソースに移動]** を選択します。 クラスター ウィンドウには、次の情報が表示されます。

    ![HDI Azure portal クラスターの概要](./media/hdinsight-hadoop-create-linux-clusters-portal/hdinsight-create-cluster-completed.png "クラスターのプロパティ")

    ウィンドウのいくつかのアイコンの説明は以下のとおりです。

    |プロパティ | 説明 |
    |---|---|
    |概要|クラスターに関するすべての重要な情報が提供されます。 たとえば、名前、属しているリソース グループ、場所、オペレーティング システム、クラスター ダッシュボードの URL などです。|
    |クラスター ダッシュボード|クラスターに関連付けられている Ambari ポータルに移動します。|
    |SSH およびクラスターのログイン|SSH を使用してクラスターにアクセスするために必要な情報が提供されます。|
    |削除|HDInsight クラスターを削除します。|

## <a name="customize-clusters"></a>クラスターのカスタマイズ

* [ブートストラップを使って HDInsight クラスターをカスタマイズする](hdinsight-hadoop-customize-cluster-bootstrap.md)
* [スクリプト アクションを使用して Linux ベースの HDInsight クラスターをカスタマイズする](hdinsight-hadoop-customize-cluster-linux.md)

## <a name="delete-the-cluster"></a>クラスターを削除する

[!INCLUDE [delete-cluster-warning](../../includes/hdinsight-delete-cluster-warning.md)]

## <a name="troubleshoot"></a>トラブルシューティング

HDInsight クラスターの作成で問題が発生した場合は、「[アクセス制御の要件](hdinsight-hadoop-create-linux-clusters-portal.md)」を参照してください。

## <a name="next-steps"></a>次の手順

HDInsight クラスターが正常に作成されました。 次に、クラスターを操作する方法を学習してください。

### <a name="apache-hadoop-clusters"></a>Apache Hadoop クラスター

* [HDInsight での Apache Hive の使用](hadoop/hdinsight-use-hive.md)
* [HDInsight での MapReduce の使用](hadoop/hdinsight-use-mapreduce.md)

### <a name="apache-hbase-clusters"></a>Apache HBase クラスター

* [HDInsight での Apache HBase の使用](hbase/apache-hbase-tutorial-get-started-linux.md)
* [HDInsight での Apache HBase の Java アプリケーションの開発](hbase/apache-hbase-build-java-maven-linux.md)

### <a name="apache-storm-clusters"></a>Apache Storm クラスター

* [HDInsight での Apache Storm の Java トポロジの開発](storm/apache-storm-develop-java-topology.md)
* [HDInsight の Apache Storm での Python コンポーネントの使用](storm/apache-storm-develop-python-topology.md)
* [Deploy and monitor topologies with Apache Storm on HDInsight (HDInsight の Storm を使用したトポロジのデプロイと監視)](storm/apache-storm-deploy-monitor-topology-linux.md)

### <a name="apache-spark-clusters"></a>Apache Spark クラスター

* [Scala を使用してスタンドアロン アプリケーションを作成する](spark/apache-spark-create-standalone-application.md)
* [Apache Livy を使用して Apache Spark クラスターでジョブをリモートから実行する](spark/apache-spark-livy-rest-interface.md)
* [Apache Spark と BI:HDInsight と BI ツールで Spark を使用して対話型データ分析を実行する](spark/apache-spark-use-bi-tools.md)
* [Apache Spark と Machine Learning:HDInsight で Spark を使用して食品の検査結果を予測する](spark/apache-spark-machine-learning-mllib-ipython.md)
